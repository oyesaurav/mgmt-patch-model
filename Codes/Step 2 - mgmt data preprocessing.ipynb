{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "136633d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d15bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (32,32)\n",
    "Case_Num = 5  # Creating Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7724eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For reading the Images and append it to a list\n",
    "\n",
    "\n",
    "def Reading_Data():\n",
    "    from tqdm import tqdm \n",
    "    import cv2  # Used for Images processing.\n",
    "    import shutil\n",
    "    class_num = 0\n",
    "    workdir=os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "    for category in workdir:\n",
    "        Category_Path = os.path.join(Work_Dir, category + '/')\n",
    "        print(Category_Path)\n",
    "        print(class_num)\n",
    "        categorydir = os.listdir(Category_Path)\n",
    "        print(categorydir)\n",
    "        if '.DS_Store' in categorydir:\n",
    "            categorydir.remove('.DS_Store')\n",
    "        print(categorydir)\n",
    "        for patient in categorydir:\n",
    "            Patient_Path = os.path.join(Category_Path, patient + '/')\n",
    "            for img in os.listdir(Patient_Path):  # listing all images present in the category folder.\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(Patient_Path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                    data.append([img_array, class_num])  # Saving images with their corresponding class labels.\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        class_num = 1\n",
    "        shutil.rmtree(Category_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a02cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "\n",
    "def Initilizing_Features_Labels():\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    print('List Size: ', len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4afa161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "\n",
    "def Converting(block_h, block_w):\n",
    "    import numpy as np  # Used for array operations.\n",
    "    global X, y\n",
    "    \n",
    "    X = np.array(X).reshape((-1, block_h, block_w, 1))  # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7bf7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Storing Preprocessed data in the file.\n",
    "\n",
    "def Storing_Preprocessed_data(X_train, X_test, y_train, y_test, case_number):\n",
    "    import pickle  # To save the data or Trained Deep learning model in the File.\n",
    "    \n",
    "    # Storing Features & Labels\n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train, pickle_out)  # Storing Training Features\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test, pickle_out)  # Storing testing Features\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train, pickle_out)  # Storing Training Labels\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test, pickle_out)  # Storing testing Labels\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20823e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Dividing Datasets into number of cases for Cross Validation\n",
    "\n",
    "def Creating_Cases(Case_Num):\n",
    "    import shutil\n",
    "    import os\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "    for case in range(Case_Num):\n",
    "        CASES.append('Case_'+ str(case + 1))\n",
    "\n",
    "    # Creating Cases\n",
    "    try:\n",
    "        for case in CASES:\n",
    "            os.mkdir(Work_Dir + case)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    case_number = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        Storing_Preprocessed_data(X_train, X_test, y_train, y_test, case_number)\n",
    "        \n",
    "        case_number = case_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1450e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the total data: 0\n",
      "List Size:  0 0\n",
      "Array Size with Reshape:  0 0\n",
      "Array Shape with Reshape:  (0, 32, 32, 1) (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step 2 - mgmt data preprocessing.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=35'>36</a>\u001b[0m \u001b[39m# Function Call --> Dividing Datasets into number of cases for Cross Validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=36'>37</a>\u001b[0m CASES \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=37'>38</a>\u001b[0m Creating_Cases(Case_Num)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=39'>40</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDone..!!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step 2 - mgmt data preprocessing.ipynb Cell 7'\u001b[0m in \u001b[0;36mCreating_Cases\u001b[0;34m(Case_Num)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=18'>19</a>\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=19'>20</a>\u001b[0m case_number \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m kf\u001b[39m.\u001b[39msplit(X):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=21'>22</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=22'>23</a>\u001b[0m     \u001b[39m#print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=23'>24</a>\u001b[0m     X_train, X_test \u001b[39m=\u001b[39m X[train_index], X[test_index]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000006?line=24'>25</a>\u001b[0m     y_train, y_test \u001b[39m=\u001b[39m y[train_index], y[test_index]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py:333\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=330'>331</a>\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=331'>332</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[0;32m--> <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=332'>333</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=333'>334</a>\u001b[0m         (\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=334'>335</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=335'>336</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=336'>337</a>\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=337'>338</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=339'>340</a>\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    <a href='file:///Users/vitthal/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py?line=340'>341</a>\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "# All Function Calls\n",
    "import os\n",
    "import random\n",
    "import numpy as np  # Used for array operations.\n",
    "import pickle\n",
    "\n",
    "PATH = path + 'Data/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "\n",
    "# Calling Functions:\n",
    "\n",
    "# Creating list for storing processed data\n",
    "data = []\n",
    "\n",
    "# Function Call --> For reading the Images and append it to a list\n",
    "Reading_Data()\n",
    "\n",
    "# Printing Length of the total data.\n",
    "print('Length of the total data: ' + str(len(data)))\n",
    "\n",
    "# Randomly Shuffling and printing data for unbiased model.\n",
    "random.shuffle(data)\n",
    "for sample in data[:50]:\n",
    "    print(sample[1], end=' ')\n",
    "\n",
    "# Initilizing all features & labels of the processed image in the list X & Y.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Function Call --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "Initilizing_Features_Labels()\n",
    "\n",
    "# Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "Converting(block_h, block_w)\n",
    "\n",
    "# Function Call --> Dividing Datasets into number of cases for Cross Validation\n",
    "CASES = []\n",
    "Creating_Cases(Case_Num)\n",
    "\n",
    "os.chdir(PATH)\n",
    "print('Done..!!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
