{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "136633d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40d15bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (32,32)\n",
    "Case_Num = 5  # Creating Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7724eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For reading the Images and append it to a list\n",
    "\n",
    "\n",
    "def Reading_Data():\n",
    "    from tqdm import tqdm \n",
    "    import cv2  # Used for Images processing.\n",
    "    import shutil\n",
    "    class_num = 0\n",
    "    workdir=os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "    for category in workdir:\n",
    "        Category_Path = os.path.join(Work_Dir, category + '/')\n",
    "        print(Category_Path)\n",
    "        print(class_num)\n",
    "        categorydir = os.listdir(Category_Path)\n",
    "        print(categorydir)\n",
    "        if '.DS_Store' in categorydir:\n",
    "            categorydir.remove('.DS_Store')\n",
    "        print(categorydir)\n",
    "        for patient in categorydir:\n",
    "            Patient_Path = os.path.join(Category_Path, patient + '/')\n",
    "            for img in os.listdir(Patient_Path):  # listing all images present in the category folder.\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(Patient_Path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                    data.append([img_array, class_num])  # Saving images with their corresponding class labels.\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        class_num = 1\n",
    "        shutil.rmtree(Category_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21a02cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "\n",
    "def Initilizing_Features_Labels():\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    print('List Size: ', len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4afa161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "\n",
    "def Converting(block_h, block_w):\n",
    "    import numpy as np  # Used for array operations.\n",
    "    global X, y\n",
    "    \n",
    "    X = np.array(X).reshape(-1, block_h, block_w, 1)  # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7bf7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Storing Preprocessed data in the file.\n",
    "\n",
    "def Storing_Preprocessed_data(X_train, X_test, y_train, y_test, case_number):\n",
    "    import pickle  # To save the data or Trained Deep learning model in the File.\n",
    "    \n",
    "    # Storing Features & Labels\n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train, pickle_out)  # Storing Training Features\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test, pickle_out)  # Storing testing Features\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train, pickle_out)  # Storing Training Labels\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Work_Dir + 'Case_{}'.format(case_number) + '/y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test, pickle_out)  # Storing testing Labels\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20823e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Dividing Datasets into number of cases for Cross Validation\n",
    "\n",
    "def Creating_Cases(Case_Num):\n",
    "    import shutil\n",
    "    import os\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "    for case in range(Case_Num):\n",
    "        CASES.append('Case_'+ str(case + 1))\n",
    "\n",
    "    # Creating Cases\n",
    "    try:\n",
    "        for case in CASES:\n",
    "            os.mkdir(Work_Dir + case)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    case_number = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        Storing_Preprocessed_data(X_train, X_test, y_train, y_test, case_number)\n",
    "        \n",
    "        case_number = case_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1450e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/UPENN/Working_Data/MGMT_positive /\n",
      "0\n",
      "['UPENN-GBM-00095_11', '.DS_Store', 'UPENN-GBM-00128_11', 'UPENN-GBM-00098_11', 'UPENN-GBM-00124_11', 'UPENN-GBM-00115_11']\n",
      "['UPENN-GBM-00095_11', 'UPENN-GBM-00128_11', 'UPENN-GBM-00098_11', 'UPENN-GBM-00124_11', 'UPENN-GBM-00115_11']\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/UPENN/Working_Data/MGMT_negative/\n",
      "1\n",
      "['UPENN-GBM-00091_11', '.DS_Store', 'UPENN-GBM-00022_11', 'UPENN-GBM-00088_11', 'UPENN-GBM-00092_11', 'UPENN-GBM-00034_11']\n",
      "['UPENN-GBM-00091_11', 'UPENN-GBM-00022_11', 'UPENN-GBM-00088_11', 'UPENN-GBM-00092_11', 'UPENN-GBM-00034_11']\n",
      "Length of the total data: 32977\n",
      "0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 List Size:  32977 32977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/0nrgl50n1ln9bwhj847f2gy00000gn/T/ipykernel_16694/3290791079.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(X).reshape(-1, block_h, block_w, 1)  # -1 is added to solve dimension mismatch while converting list to an array.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32977 into shape (32,32,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step 2 - mgmt data preprocessing.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=30'>31</a>\u001b[0m Initilizing_Features_Labels()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=32'>33</a>\u001b[0m \u001b[39m# Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=33'>34</a>\u001b[0m Converting(block_h, block_w)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=35'>36</a>\u001b[0m \u001b[39m# Function Call --> Dividing Datasets into number of cases for Cross Validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000007?line=36'>37</a>\u001b[0m CASES \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step 2 - mgmt data preprocessing.ipynb Cell 5'\u001b[0m in \u001b[0;36mConverting\u001b[0;34m(block_h, block_w)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m  \u001b[39m# Used for array operations.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39mglobal\u001b[39;00m X, y\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000004?line=6'>7</a>\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(X)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, block_h, block_w, \u001b[39m1\u001b[39;49m)  \u001b[39m# -1 is added to solve dimension mismatch while converting list to an array.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000004?line=7'>8</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Codes/Step%202%20-%20mgmt%20data%20preprocessing.ipynb#ch0000004?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mArray Size with Reshape: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(X), \u001b[39mlen\u001b[39m(y))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 32977 into shape (32,32,1)"
     ]
    }
   ],
   "source": [
    "# All Function Calls\n",
    "import os\n",
    "import random\n",
    "import numpy as np  # Used for array operations.\n",
    "import pickle\n",
    "\n",
    "PATH = path + 'Data/UPENN/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "\n",
    "# Calling Functions:\n",
    "\n",
    "# Creating list for storing processed data\n",
    "data = []\n",
    "\n",
    "# Function Call --> For reading the Images and append it to a list\n",
    "Reading_Data()\n",
    "\n",
    "# Printing Length of the total data.\n",
    "print('Length of the total data: ' + str(len(data)))\n",
    "\n",
    "# Randomly Shuffling and printing data for unbiased model.\n",
    "random.shuffle(data)\n",
    "for sample in data[:50]:\n",
    "    print(sample[1], end=' ')\n",
    "\n",
    "# Initilizing all features & labels of the processed image in the list X & Y.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Function Call --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "Initilizing_Features_Labels()\n",
    "\n",
    "# Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "Converting(block_h, block_w)\n",
    "\n",
    "# Function Call --> Dividing Datasets into number of cases for Cross Validation\n",
    "CASES = []\n",
    "Creating_Cases(Case_Num)\n",
    "\n",
    "os.chdir(PATH)\n",
    "print('Done..!!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
