{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (32,32)\n",
    "Case_Num = 5  # Creating Number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For reading the Images and append it to a list\\n\n",
    "def Reading_Data():\n",
    "    from tqdm import tqdm\n",
    "    import cv2  # Used for Images processing.\n",
    "    import shutil\n",
    "    class_num = 0\n",
    "    workdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "    for category in workdir:\n",
    "        Category_Path = os.path.join(Work_Dir, category + '/')\n",
    "        print(Category_Path)\n",
    "        print(class_num)\n",
    "        categorydir = os.listdir(Category_Path)\n",
    "        print(categorydir)\n",
    "        if '.DS_Store' in categorydir:\n",
    "            categorydir.remove('.DS_Store')\n",
    "        print(categorydir)\n",
    "        for patient in categorydir:\n",
    "            Patient_Path = os.path.join(Category_Path, patient + '/')\n",
    "            # listing all images present in the category folder.\n",
    "            for img in os.listdir(Patient_Path):\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(\n",
    "                        Patient_Path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                    # Saving images with their corresponding class labels.\n",
    "                    data.append([img_array, class_num])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        class_num = 1\n",
    "        shutil.rmtree(Category_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "\n",
    "def Initilizing_Features_Labels():\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    print('List Size: ', len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "\n",
    "def Converting(block_h, block_w):\n",
    "    import numpy as np  # Used for array operations.\n",
    "    global X, y\n",
    "\n",
    "    # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    X = np.array(X).reshape((-1, block_h, block_w, 1))\n",
    "    y = np.array(y)\n",
    "\n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Storing Preprocessed data in the file.\n",
    "\n",
    "def Storing_Preprocessed_data(X_train, X_test, y_train, y_test, case_number):\n",
    "    # To save the data or Trained Deep learning model in the File.\n",
    "    import pickle\n",
    "\n",
    "    # Storing Features & Labels\n",
    "    pickle_out = open(\n",
    "        Work_Dir + 'Case_{}'.format(case_number) + '/X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train, pickle_out)  # Storing Training Features\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(\n",
    "        Work_Dir + 'Case_{}'.format(case_number) + '/X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test, pickle_out)  # Storing testing Features\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(\n",
    "        Work_Dir + 'Case_{}'.format(case_number) + '/y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train, pickle_out)  # Storing Training Labels\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(\n",
    "        Work_Dir + 'Case_{}'.format(case_number) + '/y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test, pickle_out)  # Storing testing Labels\n",
    "    pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Dividing Datasets into number of cases for Cross Validation\n",
    "\n",
    "def Creating_Cases(Case_Num):\n",
    "    import shutil\n",
    "    import os\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "    for case in range(Case_Num):\n",
    "        CASES.append('Case_' + str(case + 1))\n",
    "\n",
    "    # Creating Cases\n",
    "    try:\n",
    "        for case in CASES:\n",
    "            os.mkdir(Work_Dir + case)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    case_number = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        Storing_Preprocessed_data(\n",
    "            X_train, X_test, y_train, y_test, case_number)\n",
    "\n",
    "        case_number = case_number + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Function Calls\n",
    "import os\n",
    "import random\n",
    "import numpy as np  # Used for array operations.\n",
    "import pickle\n",
    "\n",
    "PATH = path + 'Data/UPENN/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "\n",
    "# Calling Functions:\n",
    "\n",
    "# Creating list for storing processed data\n",
    "data = []\n",
    "\n",
    "# Function Call --> For reading the Images and append it to a list\n",
    "Reading_Data()\n",
    "\n",
    "# Printing Length of the total data.\n",
    "print('Length of the total data: ' + str(len(data)))\n",
    "\n",
    "# Randomly Shuffling and printing data for unbiased model.\n",
    "random.shuffle(data)\n",
    "for sample in data[:50]:\n",
    "    print(sample[1], end=' ')\n",
    "\n",
    "# Initilizing all features & labels of the processed image in the list X & Y.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Function Call --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "Initilizing_Features_Labels()\n",
    "\n",
    "# Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "Converting(block_h, block_w)\n",
    "\n",
    "# Function Call --> Dividing Datasets into number of cases for Cross Validation\n",
    "CASES = []\n",
    "Creating_Cases(Case_Num)\n",
    "\n",
    "os.chdir(PATH)\n",
    "print('Done..!!')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
