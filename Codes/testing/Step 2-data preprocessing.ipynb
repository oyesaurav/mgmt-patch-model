{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varialble definations\n",
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (120,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For reading the Images and append it to a list\n",
    "\n",
    "def Reading_Data():\n",
    "    # It is a progress bar, Used to track the estimated remaining time.\n",
    "    from tqdm import tqdm\n",
    "    import cv2  # Used for Images processing.\n",
    "    print(\"Reading Data\")\n",
    "    splitpath = os.listdir(Split_Path)\n",
    "    if '.DS_Store' in splitpath:\n",
    "        splitpath.remove('.DS_Store')\n",
    "    for category in splitpath:\n",
    "        # Joining path for \"MGMT_positive & MGMT_negative\".\n",
    "        Category_Path = os.path.join(Split_Path, category + '/')\n",
    "        print(Category_Path)\n",
    "        # Initializing index for each class.\n",
    "        class_num = os.listdir(Split_Path).index(category)\n",
    "        print(class_num)\n",
    "        categorypath = os.listdir(Category_Path)\n",
    "        if '.DS_Store' in categorypath:\n",
    "            categorypath.remove('.DS_Store')\n",
    "        # Working with the folders of images\n",
    "        # print(categorypath)\n",
    "        # for img_folder in tqdm(categorypath):\n",
    "            # print(img_folder)\n",
    "        Img_Path = Category_Path +'/'\n",
    "\n",
    "        # listing all images present in the image folder.\n",
    "        img_list = os.listdir(Img_Path)\n",
    "        if '.DS_Store' in img_list:\n",
    "            img_list.remove('.DS_Store')\n",
    "            print(\"Removed .DS_Store\")\n",
    "        \n",
    "        for img in img_list:\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(\n",
    "                    Img_Path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                # Saving images with their corresponding class labels.\n",
    "                training_data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "\n",
    "def Initilizing_Features_Labels():\n",
    "    print(\"Initilizing Features & Labels\")\n",
    "    for features, label in training_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    print('List Size: ', len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "\n",
    "def Converting(block_h, block_w):\n",
    "    import numpy as np  # Used for array operations.\n",
    "    global X, y\n",
    "    print(\"Converting into Numpy Array\")\n",
    "\n",
    "    # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    X = np.array(X).reshape(-1, block_h, block_w, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Storing Preprocessed data in the file.\n",
    "\n",
    "def Storing_Preprocessed_data():\n",
    "    # To save the data or Trained Deep learning model in the File.\n",
    "    import pickle\n",
    "    print(\"Storing Preprocessed Data\")\n",
    "    # Storing Training Features & Labels\n",
    "    pickle_out = open(Split_Path + '/X.pickle', 'wb')\n",
    "    pickle.dump(X, pickle_out)  # Storing Training Features\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(Split_Path + '/y.pickle', 'wb')\n",
    "    pickle.dump(y, pickle_out)  # Storing Training Labels\n",
    "    pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> removing .DS_Store files to avoid errors in feautre labelling\n",
    "def remove_ds_store():\n",
    "    import os\n",
    "    import shutil\n",
    "    print('Removing .DS_Store')\n",
    "    workdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "        print(\"Removed .DS_Store from Work_Dir : {}\".format(Work_Dir))\n",
    "    for case in workdir:\n",
    "        try:\n",
    "            Case_Path = os.path.join(Work_Dir, case + '/')\n",
    "            casepath = os.listdir(Case_Path)\n",
    "            if '.DS_Store' in casepath:\n",
    "                casepath.remove('.DS_Store')\n",
    "                print(\"Removed .DS_Store from Case_Path : {}\".format(Case_Path))\n",
    "            for Type in casepath:\n",
    "                Type_Path = os.path.join(Case_Path, Type + '/')\n",
    "                typepath = os.listdir(Type_Path)\n",
    "                if '.DS_Store' in typepath:\n",
    "                    typepath.remove('.DS_Store')\n",
    "                    print(\"Removed .DS_Store from Type_Path : {}\".format(Type_Path))\n",
    "                for patient in typepath:\n",
    "                    Patient_Path = os.path.join(Type_Path, patient + '/')\n",
    "                    patientpath = os.listdir(Patient_Path)\n",
    "                    if '.DS_Store' in patientpath:\n",
    "                        patientpath.remove('.DS_Store')\n",
    "                        print(\"Removed .DS_Store from Patient_Path : {}\".format(\n",
    "                            Patient_Path))\n",
    "                    for file in patientpath:\n",
    "                        file_Path = os.path.join(Patient_Path, file)\n",
    "                        if file_Path.endswith('.DS_Store'):\n",
    "                            os.remove(file_Path)\n",
    "                            print(\n",
    "                                \"Removed .DS_Store from file_Path : {}\".format(file_Path))\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_5/train/MGMT_positive/\n",
      "0\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_5/train/MGMT_negative/\n",
      "1\n",
      "Case_5\n",
      "Length of the total training data: 16592\n",
      "1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 Initilizing Features & Labels\n",
      "List Size:  16592 16592\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  16592 16592\n",
      "Array Shape with Reshape:  (16592, 120, 120, 1) (16592,)\n",
      "Storing Preprocessed Data\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_2/train/MGMT_positive/\n",
      "0\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_2/train/MGMT_negative/\n",
      "1\n",
      "Case_2\n",
      "Length of the total training data: 16413\n",
      "0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 Initilizing Features & Labels\n",
      "List Size:  16413 16413\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  16413 16413\n",
      "Array Shape with Reshape:  (16413, 120, 120, 1) (16413,)\n",
      "Storing Preprocessed Data\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_3/train/MGMT_positive/\n",
      "0\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_3/train/MGMT_negative/\n",
      "1\n",
      "Case_3\n",
      "Length of the total training data: 16571\n",
      "0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 Initilizing Features & Labels\n",
      "List Size:  16571 16571\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  16571 16571\n",
      "Array Shape with Reshape:  (16571, 120, 120, 1) (16571,)\n",
      "Storing Preprocessed Data\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_4/train/MGMT_positive/\n",
      "0\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_4/train/MGMT_negative/\n",
      "1\n",
      "Case_4\n",
      "Length of the total training data: 16450\n",
      "0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 Initilizing Features & Labels\n",
      "List Size:  16450 16450\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  16450 16450\n",
      "Array Shape with Reshape:  (16450, 120, 120, 1) (16450,)\n",
      "Storing Preprocessed Data\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/train/MGMT_positive/\n",
      "0\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/train/MGMT_negative/\n",
      "1\n",
      "Case_1\n",
      "Length of the total training data: 16802\n",
      "1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 Initilizing Features & Labels\n",
      "List Size:  16802 16802\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  16802 16802\n",
      "Array Shape with Reshape:  (16802, 120, 120, 1) (16802,)\n",
      "Storing Preprocessed Data\n",
      "Done..!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling all functions\n",
    "import os\n",
    "import random\n",
    "import numpy as np  # Used for array operations.\n",
    "import pickle\n",
    "\n",
    "PATH = path + 'Data/BRATS/mod_data1/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "workdir = os.listdir(Work_Dir)\n",
    "if '.DS_Store' in workdir:\n",
    "    workdir.remove('.DS_Store')\n",
    "# Calling Functions:\n",
    "remove_ds_store()\n",
    "\n",
    "for case in workdir:\n",
    "    Case_Path = os.path.join(Work_Dir, case)  # Joining \"Cases\" path.\n",
    "\n",
    "    # Joining \"train\" folder with \"Cases\" path.\n",
    "    Split_Path = Case_Path + '/train/'\n",
    "\n",
    "    # Creating list for storing processed data\n",
    "    training_data = []\n",
    "\n",
    "    # Function Call --> For reading the Images and append it to a list\n",
    "    Reading_Data()\n",
    "\n",
    "    # Printing Length of the training data.\n",
    "    print(case)\n",
    "    print('Length of the total training data: ' + str(len(training_data)))\n",
    "\n",
    "    # Randomly Shuffling and printing data for unbiased model.\n",
    "    random.shuffle(training_data)\n",
    "    for sample in training_data[:50]:\n",
    "        print(sample[1], end=' ')\n",
    "\n",
    "    # Initilizing all features & labels of the processed image in the list X & Y.\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Function Call --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "    Initilizing_Features_Labels()\n",
    "\n",
    "    # Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "    Converting(block_h, block_w)\n",
    "\n",
    "    # Function Call --> Storing Preprocessed data in the file.\n",
    "    Storing_Preprocessed_data()\n",
    "\n",
    "\n",
    "os.chdir(PATH)\n",
    "print('Done..!!')\n",
    "os.system('say \"your program has finished\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
