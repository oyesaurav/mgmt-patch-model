{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definations\n",
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "\n",
    "CATEGORIES = ['MGMT_negative', 'MGMT_positive']\n",
    "\n",
    "block_h, block_w = (120, 120)\n",
    "stride = 3\n",
    "\n",
    "Case_Num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create backup of the data and create working directory\n",
    "\n",
    "def Backup():\n",
    "    import shutil\n",
    "    print('Backing up the files')\n",
    "    # Copying data for backup\n",
    "    try:\n",
    "        shutil.copytree(PATH, Org_Dir)\n",
    "    except:\n",
    "        print('Backup already exists')\n",
    "    # Copying data for working\n",
    "    try:\n",
    "        shutil.copytree(Org_Dir, Work_Dir)\n",
    "    except:\n",
    "        print('Working directory already exists')\n",
    "    \n",
    "    # Deleting folders\n",
    "    for category in CATEGORIES:\n",
    "        try:\n",
    "            shutil.rmtree(PATH + category)\n",
    "        except:\n",
    "            print('Folder already deleted')\n",
    "    print('Backup complete')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function Defination --> Super Resolution as alternative to Interpolation\n",
    "# import time\n",
    "# import cv2\n",
    "# from cv2 import dnn_superres\n",
    "# import os\n",
    "\n",
    "# def super_res(img):\n",
    "#     # Create an object\n",
    "#     sr = dnn_superres.DnnSuperResImpl_create()\n",
    "#     # Image already has type np.ndarray no need to read the image from the path\n",
    "#     # Read the desired model\n",
    "#     model_path= path + 'testing/models/FSRCNN_x2.pb'\n",
    "#     sr.readModel(model_path)\n",
    "\n",
    "#     # Set the desired model and scale to get correct pre- and post-processing\n",
    "#     sr.setModel(\"fsrcnn\", 2)\n",
    "\n",
    "#     # Upscale the image\n",
    "#     result = sr.upsample(img)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Generate Tumor Images of Patients\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def Generate_images():\n",
    "    from tqdm import tqdm\n",
    "    import cv2\n",
    "    print('Generating Images')\n",
    "    try:\n",
    "        workdir = os.listdir(Work_Dir)\n",
    "        if '.DS_Store' in workdir:\n",
    "            workdir.remove('.DS_Store')\n",
    "        for case in workdir:\n",
    "            Case_Path = os.path.join(Work_Dir, case + '/')\n",
    "            casepath = os.listdir(Case_Path)\n",
    "            if '.DS_Store' in casepath:\n",
    "                casepath.remove('.DS_Store')\n",
    "            for split in casepath:\n",
    "                Split_Path = os.path.join(Case_Path, split + '/')\n",
    "                \n",
    "                splitpath = os.listdir(Split_Path)\n",
    "                if '.DS_Store' in splitpath:\n",
    "                    splitpath.remove('.DS_Store')\n",
    "                for category in tqdm(splitpath):\n",
    "                    Category_Path = os.path.join(Split_Path, category + '/')\n",
    "                    os.chdir(Category_Path)\n",
    "                    list_of_patients = []\n",
    "                    categorypath = os.listdir(Category_Path)\n",
    "                    if '.DS_Store' in categorypath:\n",
    "                        categorypath.remove('.DS_Store')\n",
    "                    for file in tqdm(categorypath):\n",
    "                        patient = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "                        if patient not in list_of_patients:\n",
    "                            list_of_patients.append(patient)\n",
    "                            flair = nib.load('{}_flair.nii.gz'.format(patient))\n",
    "                            flair_data = flair.get_fdata()  # Converting nii to 3d np array\n",
    "                            seg_mask = nib.load(\n",
    "                                '{}_seg.nii.gz'.format(patient))\n",
    "                            seg_mask_data = seg_mask.get_fdata()  # Converting nii to 3d np array\n",
    "                            # print(\"Loaded flair and seg_mask for patient {}\".format(patient))\n",
    "                            #Extracting only those layers from mask hich have non zero values\n",
    "                            z = np.any(seg_mask_data, axis=(0, 1))\n",
    "                            # zmin & zmax saves the corresponding layer numbers of tumor regions\n",
    "                            zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "                            #Creating a new mask to remove segmentation\n",
    "                            d = seg_mask_data\n",
    "                            for layer in range(zmin, zmax+1):\n",
    "                                nonzero = np.nonzero(d[:, :, layer])\n",
    "                                r = nonzero[0]\n",
    "                                c = nonzero[1]\n",
    "                                if (r.size == 0 or c.size == 0):\n",
    "                                    continue\n",
    "                                rmin = np.min(r)\n",
    "                                rmax = np.max(r)\n",
    "                                cmin = np.min(c)\n",
    "                                cmax = np.max(c)\n",
    "                                # Replacing tumor region values by 1\n",
    "                                d[rmin:rmax+1, cmin:cmax+1, layer] = 1\n",
    "\n",
    "                            #Multiplying flair data with new mask\n",
    "                            tumor = np.multiply(flair_data, d)\n",
    "\n",
    "                            #Removing zero valued layers\n",
    "                            tumor_layers = tumor[:, :, ~\n",
    "                                                 (tumor == 0).all((0, 1))]\n",
    "                                                 \n",
    "                            # Removing layers having less than 500 pixels of tumor\n",
    "                            tumor_layers = tumor_layers[:, :, np.count_nonzero(tumor_layers, axis=(0, 1)) > 1000]\n",
    "\n",
    "                            #converting to png files\n",
    "                            Cropped_list = []  # list containing cropped 2d layers of tumor region\n",
    "                            for lay in range(0, tumor_layers.shape[2]):\n",
    "                                coords = np.argwhere(tumor_layers[:, :, lay])\n",
    "                                x_min, y_min = coords.min(axis=0)\n",
    "                                x_max, y_max = coords.max(axis=0)\n",
    "                                cropped = tumor_layers[x_min:x_max +\n",
    "                                                       1, y_min:y_max+1, lay]\n",
    "                                # normalization/scaling\n",
    "                                cropped *= (255.0/cropped.max())\n",
    "                                Cropped_list.append(cropped)\n",
    "\n",
    "                            frame = 0\n",
    "                            # print('Saving images')\n",
    "                            for item in Cropped_list:\n",
    "                                \n",
    "                                # item is numpy.ndarray\n",
    "                                im = item\n",
    "                                # r = 150/im.shape[1]\n",
    "                                dim = (block_h, block_w)\n",
    "                                im_resized = cv2.resize(\n",
    "                                    im,dim, interpolation=cv2.INTER_CUBIC)  \n",
    "                                # print(\"read cv2\")\n",
    "                                cv2.imwrite(\"{}_img_{}.png\".format(patient,frame),im_resized)\n",
    "                                frame =frame+1\n",
    "                                # im = Image.fromarray(item)\n",
    "                                # im = im.convert('L')\n",
    "                                # width, height = im.size\n",
    "                                # print(item.shape[0], item.shape[1])\n",
    "                                # print(\"width = {} height = {}\".format(width, height))\n",
    "                                # if ((item.shape[0]*item.shape[1]) >= 300):\n",
    "                                #     print(\"here\")\n",
    "                                #     frame = frame + 1\n",
    "                                #     im = cv2.imread(item)\n",
    "                                #     im_resized = cv2.resize( im, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_CUBIC)  # type: ignore\n",
    "                                #     # im = im.convert('L')\n",
    "                                #     # width, height = im.size\n",
    "                                #     # if (height < 120 and width >= 120):\n",
    "                                #     #     im = im.resize((150, width))\n",
    "                                #     # elif (height >= 120 and width < 120):\n",
    "                                #     #     im = im.resize((height, 32))\n",
    "                                #     # elif (height < 120 and width < 120):\n",
    "                                #     #     im = im.resize((120, 120))\n",
    "                                #     im_resized.save(\"{}_img_{}.png\".format(\n",
    "                                #         patient, frame))\n",
    "                                #     im_resized.close()\n",
    "                                # frame=frame+1\n",
    "                            \n",
    "\n",
    "                            #Removing unwanted nii files\n",
    "                            niipath = os.listdir(os.getcwd())\n",
    "                            if '.DS_Store' in niipath:\n",
    "                                niipath.remove('.DS_Store')\n",
    "                            for item in niipath:\n",
    "                                try:\n",
    "                                    if item.startswith(patient) and item.endswith(\".gz\"):\n",
    "                                        os.remove(item)\n",
    "                                except Exception as e:\n",
    "                                    print(e)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    os.chdir(Work_Dir)\n",
    "    print('Images Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Dividing Datasets into number of cases for Cross Validation\n",
    "\n",
    "def Creating_Cases(Case_Num):\n",
    "    import shutil\n",
    "    import os\n",
    "    print('Creating Cases')\n",
    "    for case in range(Case_Num):\n",
    "        CASES.append('Case_' + str(case + 1))\n",
    "\n",
    "    # Creating Case-1\n",
    "    Case = Work_Dir + 'Case_1'\n",
    "    try:\n",
    "        shutil.copytree(Work_Dir, Case)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Creating Remaining Cases\n",
    "    try:\n",
    "        for case in range(Case_Num - 1):\n",
    "            shutil.copytree(Case, Work_Dir + 'Case_' + str(case+2))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Deleting folder, listed in the CATEGORIES list, after creating Cases\n",
    "    for cate in CATEGORIES:\n",
    "        try:\n",
    "            # Deleting Folders of CATEGORIES list\n",
    "            shutil.rmtree(Work_Dir + cate)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('Cases Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Separating_Test_Data to perform K-fold Cross Validation\n",
    "\n",
    "def Separating_Test_Data():\n",
    "    import splitfolders\n",
    "    import shutil\n",
    "    from tqdm import tqdm\n",
    "    print('Seprating Test Data')\n",
    "    i = 0\n",
    "    workdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "        print(\"Removed .DS_Store\")\n",
    "    for case in tqdm(workdir):\n",
    "        try:\n",
    "            Case_Path = os.path.join(Work_Dir, case + '/')\n",
    "            casepath = os.listdir(Case_Path)\n",
    "            if '.DS_Store' in casepath:\n",
    "                casepath.remove('.DS_Store')\n",
    "            for Type in casepath:\n",
    "                Type_Path = os.path.join(Case_Path, Type + '/')\n",
    "                typepath = os.listdir(Type_Path)\n",
    "                if '.DS_Store' in typepath:\n",
    "                    typepath.remove('.DS_Store')\n",
    "                for patient in typepath:\n",
    "                    Patient_Path = os.path.join(Type_Path, patient + '/')\n",
    "                    patientpath = os.listdir(Patient_Path)\n",
    "                    if '.DS_Store' in patientpath:\n",
    "                        patientpath.remove('.DS_Store')\n",
    "                    for file in patientpath:\n",
    "                        file_Path = os.path.join(Patient_Path, file)\n",
    "                        source = file_Path\n",
    "                        destination = Type_Path\n",
    "                        shutil.copy(source, destination)\n",
    "                    shutil.rmtree(Type_Path + patient)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        input_folder = Case_Path\n",
    "        output_folder = input_folder\n",
    "        i = i+1\n",
    "        splitfolders.ratio(input_folder, output=output_folder,\n",
    "                           seed=i, ratio=(.8, .2), group_prefix=5)\n",
    "\n",
    "        # Deleting folder, listed in the CATEGORIES list, after Seprating the data\n",
    "        for cate in CATEGORIES:\n",
    "            try:\n",
    "                shutil.rmtree(Case_Path + cate)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        # Rename folder 'val' to 'test'\n",
    "        try:\n",
    "            os.rename(Case_Path + 'val', Case_Path + 'test')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('Test Data Seprated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> removing .DS_Store files to avoid errors in feautre labelling\n",
    "def remove_ds_store():\n",
    "    import os\n",
    "    import shutil\n",
    "    print('Removing .DS_Store')\n",
    "    workdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "        workdir.remove('.DS_Store')\n",
    "        print(\"Removed .DS_Store from Work_Dir : {}\".format(Work_Dir))\n",
    "    for case in workdir:\n",
    "        try:\n",
    "            Case_Path = os.path.join(Work_Dir, case + '/')\n",
    "            casepath = os.listdir(Case_Path)\n",
    "            if '.DS_Store' in casepath:\n",
    "                casepath.remove('.DS_Store')\n",
    "                print(\"Removed .DS_Store from Case_Path : {}\".format(Case_Path))\n",
    "            for Type in casepath:\n",
    "                Type_Path = os.path.join(Case_Path, Type + '/')\n",
    "                typepath = os.listdir(Type_Path)\n",
    "                if '.DS_Store' in typepath:\n",
    "                    typepath.remove('.DS_Store')\n",
    "                    print(\"Removed .DS_Store from Type_Path : {}\".format(Type_Path))\n",
    "                for patient in typepath:\n",
    "                    Patient_Path = os.path.join(Type_Path, patient + '/')\n",
    "                    patientpath = os.listdir(Patient_Path)\n",
    "                    if '.DS_Store' in patientpath:\n",
    "                        patientpath.remove('.DS_Store')\n",
    "                        print(\"Removed .DS_Store from Patient_Path : {}\".format(Patient_Path))\n",
    "                    for file in patientpath:\n",
    "                        file_Path = os.path.join(Patient_Path, file)\n",
    "                        if file_Path.endswith('.DS_Store'):\n",
    "                            os.remove(file_Path)\n",
    "                            print(\"Removed .DS_Store from file_Path : {}\".format(file_Path))\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> Reconstructing the Working Data\n",
    "def reconstruct():\n",
    "    import shutil\n",
    "    print('Reconstructing')\n",
    "    # Deleting working directory\n",
    "    shutil.rmtree(PATH+ \"Working_data/\")\n",
    "    # Copying data from backup\n",
    "    try:\n",
    "        shutil.copytree(Org_Dir, Work_Dir)\n",
    "    except:\n",
    "        print('Working directory already exists')\n",
    "\n",
    "    \n",
    "    print('Reconstruction complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/miniforge3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing\n",
      "Reconstruction complete\n",
      "Creating Cases\n",
      "Cases Created\n",
      "Seprating Test Data\n",
      "Removed .DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 400 files [00:08, 48.52 files/s]\n",
      "Copying files: 400 files [00:08, 44.69 files/s]\n",
      "Copying files: 400 files [00:08, 44.51 files/s]\n",
      "Copying files: 400 files [00:10, 38.93 files/s]\n",
      "Copying files: 400 files [00:08, 46.35 files/s]\n",
      "100%|██████████| 5/5 [01:28<00:00, 17.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Seprated\n",
      "Generating Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 30.88it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 29.16it/s]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.67s/it]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.66it/s]\n",
      "100%|██████████| 800/800 [00:26<00:00, 29.95it/s]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.41s/it]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.74it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 29.75it/s]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.62s/it]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.60it/s]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.47it/s]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.20s/it]\n",
      "100%|██████████| 200/200 [00:06<00:00, 31.58it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 29.34it/s]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.58s/it]\n",
      "100%|██████████| 800/800 [00:25<00:00, 30.98it/s]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.43it/s]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.06s/it]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.93it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.23it/s]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.54s/it]\n",
      "100%|██████████| 800/800 [00:25<00:00, 31.17it/s]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.33it/s]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.03s/it]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.98it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.01it/s]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.56s/it]\n",
      "100%|██████████| 800/800 [00:25<00:00, 31.04it/s]\n",
      "100%|██████████| 800/800 [00:26<00:00, 30.08it/s]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Generated\n",
      "Removing .DS_Store\n",
      "Removed .DS_Store from Work_Dir : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/\n",
      "Removed .DS_Store from Case_Path : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_5/\n",
      "Removed .DS_Store from Case_Path : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_2/\n",
      "Removed .DS_Store from Case_Path : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_3/\n",
      "Removed .DS_Store from Case_Path : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_4/\n",
      "Removed .DS_Store from Case_Path : /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/\n",
      "All Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Function Calls\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "PATH = path + 'Data/BRATS/mod_data1/'\n",
    "Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "\n",
    "# Function Call --> Backup Original Data For Safety Purpose\n",
    "# Backup()\n",
    "\n",
    "# Function Call --> Reconstrucint the folder structure\n",
    "reconstruct()\n",
    "\n",
    "# Function Call --> Dividing Datasets into number of cases for Cross Validation\n",
    "CASES = []\n",
    "Creating_Cases(Case_Num)\n",
    "\n",
    "# Function Call --> Seprating_Test_Data to perform K-fold Cross Validation\n",
    "Separating_Test_Data()\n",
    "\n",
    "# Function Call --> Generate Tumor Images of Patients\n",
    "Generate_images()\n",
    "\n",
    "# Function Call --> remove >.DS_store files to avoid errors in feautre labelling\n",
    "remove_ds_store()\n",
    "\n",
    "# Function Call --> Create Image Blocks\n",
    "# Creating_Image_Blocks(block_h, block_w, stride)\n",
    "\n",
    "os.chdir(path)\n",
    "print('All Done')\n",
    "os.system('say \"your program has finished\"')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
