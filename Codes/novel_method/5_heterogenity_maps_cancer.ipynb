{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import libraries and define variables\n",
    "import tensorflow as tf \n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# Define the modalities and classifications\n",
    "# modalities = ['T1', 'T1GD', 'T2', 'FLAIR']\n",
    "classifications = ['benign','malignant']\n",
    "\n",
    "# Define patch size and stride\n",
    "block_h, block_w = 64, 64\n",
    "stride = 2\n",
    "\n",
    "# Interpolated image dimestions\n",
    "inter_dim = (110, 90)\n",
    "\n",
    "# Define paths to the BraTS dataset folders\n",
    "path = 'F:/gliobastoma-mgmt-upenn/'\n",
    "\n",
    "PATH = path + 'Data/Skin Cancer/'\n",
    "Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "Task_data = PATH + 'Task_data/'\n",
    "\n",
    "# Loading the model\n",
    "Model = tf.keras.models.load_model(path + 'Outputs/'+ 'latest_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Arbitrary functions\n",
    "\n",
    "def window(p, q, flair_data):\n",
    "    W = flair_data[p:p+64, q:q+64]\n",
    "    return W\n",
    "\n",
    "\n",
    "def ML_function(Windows):\n",
    "    count = 0\n",
    "    X = np.array(Windows).reshape(-1, block_h, block_w, 1)\n",
    "    predicted_classes = np.argmax(Model(X), axis=1)\n",
    "    for val in predicted_classes:\n",
    "        if (val == 1):\n",
    "            count = count + 1\n",
    "    # print(count)\n",
    "    return count\n",
    "\n",
    "\n",
    "def fun(a, b, flair_data):\n",
    "    if (a < 0 or a > 239 or b < 0 or b > 239):\n",
    "        print(\"invalid point\")\n",
    "        return 0\n",
    "    else:\n",
    "        Windows = []\n",
    "        for x in range(a-63, a+1):\n",
    "            for y in range(b-63, b+1):\n",
    "                Windows.append(window(x, y,flair_data))\n",
    "        count_1 = ML_function(Windows)\n",
    "    return (count_1/1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Importing the weighted matrix and averaging the various modalities\n",
    "\n",
    "def Average_Weighted_Matrix():\n",
    "    taskdata =os.listdir(Task_data)\n",
    "    if '.DS_Store' in taskdata:\n",
    "        taskdata.remove('.DS_Store')\n",
    "    for type in taskdata:\n",
    "        typedir = os.path.join(Task_data, type + '/')\n",
    "        typedata = os.listdir(typedir)\n",
    "        if '.DS_Store' in typedata:\n",
    "            typedata.remove('.DS_Store')\n",
    "        for patient in tqdm(typedata):\n",
    "            patientdir = os.path.join(typedir, patient + '/')\n",
    "            os.chdir(patientdir)\n",
    "            # print(patientdir)\n",
    "\n",
    "            # Loading the weighted matrix for each modality\n",
    "            with open(patientdir + 'W_M_{}_{}.pickle'.format(patient, modalities[0]), 'rb') as f:\n",
    "                try:\n",
    "                    W_M_t1 = pickle.load(f)\n",
    "                except EOFError:\n",
    "                    W_M_t1 = None\n",
    "\n",
    "            with open(patientdir + 'W_M_{}_{}.pickle'.format(patient, modalities[1]), 'rb') as f:\n",
    "                try:\n",
    "                    W_M_t1ce = pickle.load(f)\n",
    "                except EOFError:\n",
    "                    W_M_t1ce = None\n",
    "\n",
    "            with open(patientdir + 'W_M_{}_{}.pickle'.format(patient, modalities[2]), 'rb') as f:\n",
    "                try:\n",
    "                    W_M_t2 = pickle.load(f)\n",
    "                except EOFError:\n",
    "                    W_M_t2 = None\n",
    "\n",
    "            with open(patientdir + 'W_M_{}_{}.pickle'.format(patient, modalities[3]), 'rb') as f:\n",
    "                try:\n",
    "                    W_M_flair = pickle.load(f)\n",
    "                except EOFError:\n",
    "                    W_M_flair = None\n",
    "\n",
    "            # Averaging the weighted matrix\n",
    "            valid_modalities = sum(x is not None for x in [\n",
    "                                W_M_t1, W_M_t1ce, W_M_t2, W_M_flair])\n",
    "            W_M_sum = np.zeros_like(W_M_t1)\n",
    "            if W_M_t1 is not None:\n",
    "                W_M_sum += W_M_t1\n",
    "            if W_M_t1ce is not None:\n",
    "                W_M_sum += W_M_t1ce\n",
    "            if W_M_t2 is not None:\n",
    "                W_M_sum += W_M_t2\n",
    "            if W_M_flair is not None:\n",
    "                W_M_sum += W_M_flair\n",
    "            W_M = W_M_sum / valid_modalities\n",
    "\n",
    "            # Storing the averaged weighted matrix\n",
    "            with open(patientdir + '/W_M_{}_mod_average.pickle'.format(patient), 'wb') as f:\n",
    "                pickle.dump(W_M, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Generated Weighted matrix\n",
    "\n",
    "def Generate_Weighted_Matrix():\n",
    "    taskdir = os.listdir(Task_data)\n",
    "    if '.DS_Store' in taskdir:\n",
    "        taskdir.remove('.DS_Store')\n",
    "    print(\"1\")\n",
    "    for type in tqdm(taskdir):\n",
    "        # print(type)\n",
    "        Type_path = os.path.join(Task_data, type + '/')\n",
    "        typepath = os.listdir(Type_path)\n",
    "        if '.DS_Store' in typepath:\n",
    "            typepath.remove('.DS_Store')\n",
    "        print(2)\n",
    "        for patient in tqdm(typepath):\n",
    "            print(3)\n",
    "            # print(patient)\n",
    "            Patient_path = os.path.join(Type_path, patient + '/')\n",
    "            os.chdir(Patient_path)\n",
    "            img_arr=cv2.imread(patient,cv2.IMREAD_GRAYSCALE)\n",
    "            # Mod = nib.load('{}_{}.nii.gz'.format(patient, modality)) # Loading the flair image\n",
    "            # Mod_data = Mod.get_fdata()\n",
    "\n",
    "            # Normalizing the image\n",
    "            # print(3.1)\n",
    "            # for l in range(0, Mod_data.shape[2]):\n",
    "            #     if ((Mod_data[:,:,l].max()) == 0):\n",
    "            #       continue\n",
    "            #     else:\n",
    "            #         Mod_data[:,:,l] *= (255.0/Mod_data[:,:,l].max())\n",
    "                \n",
    "            # seg_mask = nib.load('{}_seg.nii.gz'.format(patient)) # Loading the segmentation mask\n",
    "            # seg_mask_data = seg_mask.get_fdata()\n",
    "\n",
    "            # Extracting only those layers from mask which have non zero values\n",
    "            # z = np.any(seg_mask_data, axis=(0, 1))\n",
    "            # nonzero_layers = np.nonzero(z)\n",
    "            # nonzero_layer_indices = nonzero_layers[0]\n",
    "            # num_layers = nonzero_layer_indices.size\n",
    "            #print(num_layers)\n",
    "            # arr = np.zeros((240,240,num_layers))\n",
    "            layer_num = 0\n",
    "\n",
    "            arr = np.zeros((240,240))\n",
    "\n",
    "            # Select the layer with maximum pixels\n",
    "\n",
    "            print(3.3)\n",
    "            #Finding indices of cancer pixels using mask data\n",
    "            # for layer in nonzero_layer_indices:\n",
    "            #     indices = np.transpose(np.nonzero(seg_mask_data[:,:,layer]))\n",
    "                #print(indices, layer)\n",
    "                # for [a,b] in indices:\n",
    "                #     arr[a,b,layer_num] = fun(a,b,layer,Mod_data)\n",
    "                # layer_num = layer_num + 1\n",
    "            \n",
    "            for [a,b] in img_arr:\n",
    "                    arr[a,b] = fun(a,b,img_arr)\n",
    "                \n",
    "            #print(np.count_nonzero(np.any(arr, axis=(0, 1))))\n",
    "            print(4)\n",
    "            #Calculating weighted average                \n",
    "            # Weighted_matrix = np.zeros((240,240))\n",
    "            # for x in range (0,240):\n",
    "            #     for y in range (0,240):\n",
    "            #         Sum = 0\n",
    "            #         num_terms = 0\n",
    "            #         print(5)\n",
    "            #         for slice_num in range (0,num_layers):\n",
    "            #             if(arr[x][y][slice_num] != 0):\n",
    "            #                 Sum = Sum + arr[x][y][slice_num]\n",
    "            #                 num_terms = num_terms + 1\n",
    "            #         if(num_terms != 0):\n",
    "            #             Weighted_matrix[x][y] = Sum/num_terms\n",
    "            Weighted_matrix = arr\n",
    "            print(Weighted_matrix.shape)\n",
    "            print(6)\n",
    "\n",
    "            #Storing Wiegted Average Matrix of the patient\n",
    "            pickle_out = open(Patient_path + '/W_M_{}.pickle'.format(patient), 'wb')\n",
    "            pickle.dump(Weighted_matrix, pickle_out)\n",
    "            pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main cell to invoke functions\n",
    "\n",
    "# Function call to generate weighted matrix\n",
    "# for modality in modalities:\n",
    "#     print(f'Calculating weighted matrix for {modality}')\n",
    "#     Generate_Weighted_Matrix(modality)\n",
    "#     break\n",
    "\n",
    "Generate_Weighted_Matrix()\n",
    "\n",
    "# Function call to average the weighted matrix\n",
    "# Average_Weighted_Matrix()\n",
    "\n",
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the weighted matrix\n",
    "\n",
    "pickle_in_positive = open(\n",
    "    'F:/gliobastoma-mgmt-upenn/Data/Task_Data/MGMT_negative/UPENN-GBM-00092_11/W_M_UPENN-GBM-00092_11_T1.pickle', 'rb')\n",
    "pickle_in_negative = open(\n",
    "    'F:/gliobastoma-mgmt-upenn/Data/Task_Data/MGMT_positive/UPENN-GBM-00287_11/W_M_UPENN-GBM-00287_11_T1.pickle', 'rb')\n",
    "\n",
    "W_M_positive = pickle.load(pickle_in_positive)\n",
    "W_M_negative = pickle.load(pickle_in_negative)\n",
    "\n",
    "plt.imshow(W_M_positive, cmap='Reds')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(W_M_negative, cmap='Reds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
