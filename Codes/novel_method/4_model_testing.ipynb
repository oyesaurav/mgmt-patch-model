{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import libraries and define variables\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as metrics\n",
    "matplotlib.use('TkAgg')\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config\n",
    "\n",
    "\n",
    "# Define the modalities and classifications\n",
    "modalities = ['T1', 'T1GD', 'T2', 'FLAIR']\n",
    "classifications = ['MGMT_positive', 'MGMT_negative']\n",
    "\n",
    "# Define patch size and stride\n",
    "block_h, block_w = 32, 32\n",
    "stride = 2\n",
    "\n",
    "# Interpolated image dimestions\n",
    "inter_dim = (110, 90)\n",
    "\n",
    "# Loading model\n",
    "load_model = 'latest_model.h5'\n",
    "\n",
    "# Define paths to the BraTS dataset folders\n",
    "path = config.MAIN_DIR\n",
    "\n",
    "PATH = config.MAIN_DIR + 'Test/'\n",
    "Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "Work_Dir = PATH + 'Working_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function Defination --> Create backup for test folder\n",
    "def Backup():\n",
    "    import shutil\n",
    "    print('Creating Backup')\n",
    "    # Copy data for backup\n",
    "    try:\n",
    "        shutil.copytree(PATH, Org_Dir) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Copy data for working\n",
    "    try:\n",
    "        shutil.copytree(Org_Dir, Work_Dir)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Deleting folder, listed in the CATEGORIES list, after creating Cases\n",
    "    for cate in classifications:\n",
    "        try:\n",
    "            shutil.rmtree(PATH + cate)  # Deleting Folders of CATEGORIES list\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('Backup Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Reconstruct folder\n",
    "def reconstruct():\n",
    "    import shutil\n",
    "    print('Reconstructing')\n",
    "    # Deleting working directory\n",
    "    shutil.rmtree(PATH + \"Working_data/\")\n",
    "    # Copying data from backup\n",
    "    try:\n",
    "        shutil.copytree(Org_Dir, Work_Dir)\n",
    "    except:\n",
    "        print('Working directory already exists')\n",
    "\n",
    "    print('Reconstruction complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Create modality folders for independent cohort\n",
    "def create_modality_folders():\n",
    "    print('Creating Modality Folders')\n",
    "    test_folder = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in test_folder:\n",
    "        test_folder.remove('.DS_Store')\n",
    "        print('Removed .DS_Store from test folder')\n",
    "    for pos_neg in tqdm(test_folder):\n",
    "        patient_folders = os.listdir(os.path.join(Work_Dir, pos_neg))\n",
    "        # print('Patient Folders: {}'.format(patient_folders))\n",
    "        if '.DS_Store' in patient_folders:\n",
    "            patient_folders.remove('.DS_Store')\n",
    "            print('Removed .DS_Store from patient folder')\n",
    "        for patient in patient_folders:\n",
    "            for modality in modalities:\n",
    "                print('Patient: ',patient)\n",
    "                modality_folder_path = os.path.join(Work_Dir, pos_neg, modality)\n",
    "                modality_patient_folder_path = os.path.join(modality_folder_path, patient)\n",
    "                # print(modality_patient_folder_path)\n",
    "                if not os.path.exists(modality_folder_path):\n",
    "                    # print('Creating folder: {}'.format(modality_folder_path))\n",
    "                    os.makedirs(modality_folder_path)\n",
    "                if not os.path.exists(modality_patient_folder_path):\n",
    "                    # print('Creating folder: {}'.format(modality_patient_folder_path))\n",
    "                    os.makedirs(modality_patient_folder_path)\n",
    "\n",
    "                modality_file_path = os.path.join(Work_Dir, pos_neg, patient, '{}_{}.nii.gz'.format(patient, modality))\n",
    "                seg_file_path = os.path.join(Work_Dir, pos_neg, patient, '{}_seg.nii.gz'.format(patient))\n",
    "\n",
    "                if os.path.exists(modality_file_path) and os.path.exists(seg_file_path):\n",
    "                   shutil.copy(modality_file_path, modality_patient_folder_path)\n",
    "                   shutil.copy(seg_file_path, modality_patient_folder_path)\n",
    "                else:\n",
    "                    print('File not found: {}'.format(modality_file_path))\n",
    "                    print('File not found: {}'.format(seg_file_path))\n",
    "            # delete the patient folder\n",
    "            shutil.rmtree(os.path.join(Work_Dir, pos_neg, patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Generating images\n",
    "def Generate_images():\n",
    "    try:\n",
    "        testdir = os.listdir(Work_Dir)\n",
    "        if '.DS_Store' in testdir:\n",
    "            testdir.remove('.DS_Store')\n",
    "            print('Removed .DS_Store from test folder')\n",
    "        for modality in testdir:\n",
    "            Modality_path = os.path.join(Work_Dir, modality + '/')\n",
    "            modalitypath = os.listdir(Modality_path)\n",
    "            if '.DS_Store' in modalitypath:\n",
    "                modalitypath.remove('.DS_Store')\n",
    "                print('Removed .DS_Store from modality folder')\n",
    "            for patient in modalitypath:\n",
    "                Patient_path = os.path.join(Modality_path, patient + '/')\n",
    "                patientpath = os.listdir(Patient_path)\n",
    "                if '.DS_Store' in patientpath:\n",
    "                    patientpath.remove('.DS_Store')\n",
    "                    print('Removed .DS_Store from patient folder')\n",
    "                for file in patientpath:\n",
    "                    File_path = os.path.join(Patient_path, file + '/')\n",
    "                    filepath = os.listdir(File_path)\n",
    "                    if '.DS_Store' in filepath:\n",
    "                        filepath.remove('.DS_Store')\n",
    "                        print('Removed .DS_Store from file folder')\n",
    "                    os.chdir(File_path)\n",
    "                    pat = file.split('_')[0]+'_'+file.split('_')[1]\n",
    "\n",
    "                    list_of_patients = []\n",
    "\n",
    "                    if pat not in list_of_patients:\n",
    "                        list_of_patients.append(pat)\n",
    "                        mod = nib.load('{}_{}.nii.gz'.format(pat, patient))\n",
    "                        mod_data = mod.get_fdata()\n",
    "                        seg_mask = nib.load('{}_seg.nii.gz'.format(pat))\n",
    "                        seg_mask_data = seg_mask.get_fdata()\n",
    "\n",
    "                        # Extracting layers from mask that have non zero values\n",
    "                        z = np.any(seg_mask_data, axis=(0,1))\n",
    "                        zmin, zmax = np.where(z)[0][[0, -1]]  #  zmin & zmax are the first and last layer number non zero values in the z axis\n",
    "\n",
    "                        # Creating a new mask to remove segmentation\n",
    "                        d = seg_mask_data\n",
    "                        for layer in range(zmin, zmax+1):\n",
    "                             nonzero = np.nonzero(d[:,:,layer])\n",
    "                             r = nonzero[0]\n",
    "                             c = nonzero[1]\n",
    "                             if (r.size == 0) or (c.size == 0):\n",
    "                                continue\n",
    "                             rmin = np.min(r)\n",
    "                             rmax = np.max(r)\n",
    "                             cmin = np.min(c)\n",
    "                             cmax = np.max(c)\n",
    "                             d[rmin:rmax+1, cmin:cmax+1, layer] = 1 #Replacing tumor region values by 1\n",
    "\n",
    "                        #  Multiply modality data with the new segmentation mask\n",
    "                        tumor = np.multiply(mod_data, d)\n",
    "\n",
    "                        # Removing Zero valued layers\n",
    "                        tumor_layers = tumor[:,:,~(tumor==0).all((0,1))]\n",
    "\n",
    "                        # Converting to png files\n",
    "                        Cropped_list = []\n",
    "                        for lay in range(0, tumor_layers.shape[2]):\n",
    "                            coords = np.argwhere(tumor_layers[:,:,lay])\n",
    "                            x_min, y_min = coords.min(axis=0)\n",
    "                            x_max, y_max = coords.max(axis=0)\n",
    "                            cropped = tumor_layers[x_min:x_max+1, y_min:y_max+1, lay]\n",
    "                            cropped *= (255.0/cropped.max()) # Normalizing the values\n",
    "                            Cropped_list.append(cropped)\n",
    "                            \n",
    "                        frame =0\n",
    "                        for item in Cropped_list:\n",
    "                            if ((item.shape[0]*item.shape[1])>= 300):\n",
    "                                frame = frame + 1\n",
    "                                im = Image.fromarray(item)\n",
    "                                im = im.convert('L')\n",
    "                                im.save('{}_{}_{}.png'.format(pat, patient, frame))\n",
    "                                im.close()\n",
    "                        \n",
    "                        # Deleting the nifti files\n",
    "                        niipath = os.listdir(File_path)\n",
    "                        if '.DS_Store' in niipath:\n",
    "                            niipath.remove('.DS_Store')\n",
    "                            print('Removed .DS_Store from nifti folder')\n",
    "                        for nii in niipath:\n",
    "                            try:\n",
    "                                if nii.startswith(pat) and nii.endswith('.gz'):\n",
    "                                    os.remove(nii)\n",
    "                            except Exception as e:\n",
    "                                print('Error in deleting nifti files')\n",
    "                                print(e)\n",
    "    except Exception as e:\n",
    "        print('Error in Generate_images()')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Interpolation\n",
    "\n",
    "def Interpolation():\n",
    "    try:\n",
    "        testdir = os.listdir(Work_Dir)\n",
    "        if '.DS_Store' in testdir:\n",
    "            testdir.remove('.DS_Store')\n",
    "            print('Removed .DS_Store from test folder')\n",
    "        for modality in testdir:\n",
    "            Modality_path = os.path.join(Work_Dir, modality + '/')\n",
    "            modalitypath = os.listdir(Modality_path)\n",
    "            if '.DS_Store' in modalitypath:\n",
    "                modalitypath.remove('.DS_Store')\n",
    "                print('Removed .DS_Store from modality folder')\n",
    "            for patient in modalitypath:\n",
    "                Patient_path = os.path.join(Modality_path, patient + '/')\n",
    "                patientpath = os.listdir(Patient_path)\n",
    "                if '.DS_Store' in patientpath:\n",
    "                    patientpath.remove('.DS_Store')\n",
    "                    print('Removed .DS_Store from patient folder')\n",
    "                for file in patientpath:\n",
    "                    File_path = os.path.join(Patient_path, file + '/')\n",
    "                    filepath = os.listdir(File_path)\n",
    "                    if '.DS_Store' in filepath:\n",
    "                        filepath.remove('.DS_Store')\n",
    "                        print('Removed .DS_Store from file folder')\n",
    "                    os.chdir(File_path)\n",
    "\n",
    "                    \n",
    "                    pngpath = os.listdir(File_path)\n",
    "                    if '.DS_Store' in pngpath:\n",
    "                        pngpath.remove('.DS_Store')\n",
    "                    for png in pngpath:\n",
    "                        try:\n",
    "                            if png.endswith('.png'):\n",
    "                                image = Image.open(png)\n",
    "                                image = image.resize(inter_dim, Image.ANTIALIAS)\n",
    "                                png1 = 'inter_' + png\n",
    "                                image.save(png1)\n",
    "                                image.close()\n",
    "                                os.remove(png)\n",
    "                        except Exception as e:\n",
    "                            print('Error in Interpolation() - pngpath')\n",
    "                            print(e)\n",
    "    except Exception as e:\n",
    "        print('Error in Interpolation()')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Creating Patches\n",
    "\n",
    "def Creating_patches(block_h, block_w, stride):\n",
    "    try:\n",
    "        testdir = os.listdir(Work_Dir)\n",
    "        if '.DS_Store' in testdir:\n",
    "            testdir.remove('.DS_Store')\n",
    "            print('Removed .DS_Store from test folder')\n",
    "        for modality in testdir:\n",
    "            Modality_path = os.path.join(Work_Dir, modality + '/')\n",
    "            modalitypath = os.listdir(Modality_path)\n",
    "            if '.DS_Store' in modalitypath:\n",
    "                modalitypath.remove('.DS_Store')\n",
    "                print('Removed .DS_Store from modality folder')\n",
    "            for patient in modalitypath:\n",
    "                Patient_path = os.path.join(Modality_path, patient + '/')\n",
    "                patientpath = os.listdir(Patient_path)\n",
    "                if '.DS_Store' in patientpath:\n",
    "                    patientpath.remove('.DS_Store')\n",
    "                    print('Removed .DS_Store from patient folder')\n",
    "                for file in patientpath:\n",
    "                    File_path = os.path.join(Patient_path, file + '/')\n",
    "                    filepath = os.listdir(File_path)\n",
    "                    if '.DS_Store' in filepath:\n",
    "                        filepath.remove('.DS_Store')\n",
    "                        print('Removed .DS_Store from file folder')\n",
    "                    \n",
    "                    # print(File_path)\n",
    "                    os.chdir(File_path)\n",
    "                    for png in tqdm(glob.glob('*.png')):\n",
    "                        img = Image.open(png)\n",
    "                        img_w, img_h = img.size\n",
    "\n",
    "                        File_Name, extentions = os.path.splitext(png)\n",
    "\n",
    "                        Save_path = Modality_path\n",
    "                        # print('Save',Save_path)\n",
    "\n",
    "                        frame_num= 0\n",
    "                        count_row = 0\n",
    "\n",
    "                        for row in range(0,img_h,stride):\n",
    "                            if (img_h-row >= block_h):\n",
    "                                count_row += 1\n",
    "                                count_col = 0\n",
    "\n",
    "                                for col in range(0, img_w, stride):\n",
    "                                    if (img_h - col >= block_w):\n",
    "                                        count_col += 1\n",
    "                                        frame_num += 1\n",
    "\n",
    "                                        box = (col, row, col +\n",
    "                                               block_w, row+block_h)\n",
    "                                        a = img.crop(box)\n",
    "                                        a.save(\n",
    "                                            Save_path + File_Name + '_row_' + str(count_row) + '_col_' + str(count_col) + '.png')\n",
    "\n",
    "                        img.close()\n",
    "                        os.remove(png)\n",
    "\n",
    "        # remove patient folders\n",
    "        for modality in testdir:\n",
    "            Modality_path = os.path.join(Work_Dir, modality + '/')\n",
    "            modalitypath = os.listdir(Modality_path)\n",
    "            if '.DS_Store' in modalitypath:\n",
    "                modalitypath.remove('.DS_Store')\n",
    "                print('Removed .DS_Store from modality folder')\n",
    "            for patient in modalitypath:\n",
    "                Patient_path = os.path.join(Modality_path, patient + '/')\n",
    "                shutil.rmtree(Patient_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error in Creating_patches()')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Read images\n",
    "\n",
    "def read_img():\n",
    "    print('Reading Images')\n",
    "    class_num = 0\n",
    "    data = []\n",
    "    testdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in testdir:\n",
    "        testdir.remove('.DS_Store')\n",
    "        print('Removed .DS_Store from test folder')\n",
    "    for pool in testdir:\n",
    "        pool_dir = Work_Dir + pool + '/'\n",
    "        pool_dir_list = os.listdir(pool_dir)\n",
    "        for folder in modalities:\n",
    "            if folder in pool_dir_list:\n",
    "                pool_dir_list.remove(folder)\n",
    "        if '.DS_Store' in pool_dir_list:\n",
    "            pool_dir_list.remove('.DS_Store')\n",
    "            print('Removed .DS_Store from pool folder')\n",
    "        for img in tqdm(pool_dir_list):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(pool_dir, img), cv2.IMREAD_GRAYSCALE)\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                print('Error in read_img()')\n",
    "                print(e)\n",
    "        class_num = 1\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Initialize features and labels\n",
    "\n",
    "def Initializing_feature_labels(data):\n",
    "    print('Initializing Features & Labels')\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        Y.append(label)\n",
    "    print('List Size: ', len(X), len(Y))\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting() Reshape the list to numpy array\n",
    "\n",
    "def Converting(block_h, block_w, X, Y):\n",
    "    print('Converting to Array')\n",
    "    global x, y\n",
    "\n",
    "    # # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    # if len(X) % (block_h * block_w) != 0:\n",
    "    #     print('Array Size without Reshape: ', len(X), len(Y))\n",
    "    # n_samples = len(X) // (block_h * block_w)\n",
    "    # n_missing = (n_samples + 1) * (block_h * block_w) - len(X)\n",
    "    # X_padded = np.pad(X, [(0, n_missing)], mode='constant')\n",
    "    # x = np.array(X_padded).reshape((n_samples + 1, block_h, block_w, 1))\n",
    "\n",
    "    # n_samples = len(X) // (block_h * block_w)\n",
    "    # x = np.array(X).reshape((n_samples, block_h, block_w, 1))\n",
    "    x = np.array(X).reshape((-1, block_h, block_w, 1))\n",
    "    y = np.array(Y)\n",
    "\n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    # print('Array Shape with Reshape: ', X.shape, y.shape)\n",
    "\n",
    "# Function Definition --> Reshape the list to numpy array\n",
    "\n",
    "\n",
    "# def Converting(block_h, block_w, X, Y):\n",
    "#     print('Converting to Array')\n",
    "#     global x, y\n",
    "\n",
    "#     # Check if number of elements is divisible by block size\n",
    "#     n_elem = len(X)\n",
    "#     prod = block_h * block_w\n",
    "#     if n_elem % prod != 0:\n",
    "#         n_elem_trunc = n_elem // prod * prod\n",
    "#         X = X[:n_elem_trunc]\n",
    "#         Y = Y[:n_elem_trunc]\n",
    "#         print(\n",
    "#             f\"Truncating arrays to {n_elem_trunc} elements to ensure divisibility by block size\")\n",
    "\n",
    "    # # Reshape arrays\n",
    "    # x = np.array(X).reshape((-1, block_h, block_w, 1))\n",
    "    # y = np.array(Y)\n",
    "\n",
    "    # print('Array Size with Reshape: ', len(X), len(y))\n",
    "    # print('Array Shape with Reshape: ', x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Creating Pickle files\n",
    "\n",
    "def create_pickle_files():\n",
    "    # list for storing preprocessing data\n",
    "    data = []\n",
    "\n",
    "    # Read Images\n",
    "    data = read_img()\n",
    "\n",
    "    # Print size of data\n",
    "    print('Size of data: ', len(data))\n",
    "\n",
    "    # Initializing all features & labels of the processed image in the list X & Y\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # Initializing the features and labels\n",
    "    X,Y = Initializing_feature_labels(data)\n",
    "\n",
    "    # Converting the list into numpy array\n",
    "    Converting(block_h, block_w, X, Y)\n",
    "\n",
    "    # Storing the numpy array in pickle file\n",
    "    pickle_out = open(PATH + \"X_test.pickle\", \"wb\")\n",
    "    pickle.dump(x, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(PATH + \"y_test.pickle\", \"wb\")\n",
    "    pickle.dump(y, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defination --> Create Testing files\n",
    "\n",
    "def Test_file_creation():\n",
    "\n",
    "    # # Create backup folder\n",
    "    print('Creating Backup Folder')\n",
    "    Backup()\n",
    "    \n",
    "    # # Create modality folders\n",
    "    print('Creating Modality Folders')\n",
    "    create_modality_folders()\n",
    "\n",
    "    # # Generate Images \n",
    "    print('Generating Images')\n",
    "    Generate_images()\n",
    "\n",
    "    # # Interpolation of images\n",
    "    print('Interpolating Images')\n",
    "    Interpolation()\n",
    "\n",
    "    # # Create patches\n",
    "    print('Creating Patches')\n",
    "    Creating_patches(block_h, block_w, stride)\n",
    "\n",
    "    # Create pickle files\n",
    "    print('Creating Pickle Files')  \n",
    "    create_pickle_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Load pickle files\n",
    "\n",
    "def Load_Data():\n",
    "    pickle_in = open(PATH + \"X_test.pickle\", \"rb\")\n",
    "    X = pickle.load(pickle_in) # Features\n",
    "\n",
    "    pickle_in = open(PATH + \"y_test.pickle\", \"rb\")\n",
    "    y = pickle.load(pickle_in) # Labels\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Load Model\n",
    "\n",
    "def Load_Model():\n",
    "    model = tf.keras.models.load_model(path + 'Outputs/' + load_model )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> PLotting AUC-ROC Curve\n",
    "\n",
    "def Plotting_AUC_ROC_Curve(X,y,model):\n",
    "    print('Plotting AUC-ROC Curve')\n",
    "    probs = model.predict(X)\n",
    "    fpr, tpr, thresholds = roc_curve(y, probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('auc_roc_curve.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Backup Folder\n",
      "Creating Backup\n",
      "[WinError 183] Cannot create a file when that file already exists: 'D:/MGMT research project/Test/Original_Data_Backup/'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'D:/MGMT research project/Test/Working_Data/'\n",
      "[WinError 3] The system cannot find the path specified: 'D:/MGMT research project/Test/MGMT_positive'\n",
      "[WinError 3] The system cannot find the path specified: 'D:/MGMT research project/Test/MGMT_negative'\n",
      "Backup Created\n",
      "Creating Modality Folders\n",
      "Creating Modality Folders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient:  UPENN-GBM-00604_11\n",
      "Patient:  UPENN-GBM-00604_11\n",
      "Patient:  UPENN-GBM-00604_11\n",
      "Patient:  UPENN-GBM-00604_11\n",
      "Patient:  UPENN-GBM-00609_11\n",
      "Patient:  UPENN-GBM-00609_11\n",
      "Patient:  UPENN-GBM-00609_11\n",
      "Patient:  UPENN-GBM-00609_11\n",
      "Patient:  UPENN-GBM-00588_11\n",
      "Patient:  UPENN-GBM-00588_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient:  UPENN-GBM-00588_11\n",
      "Patient:  UPENN-GBM-00588_11\n",
      "Patient:  UPENN-GBM-00602_11\n",
      "Patient:  UPENN-GBM-00602_11\n",
      "Patient:  UPENN-GBM-00602_11\n",
      "Patient:  UPENN-GBM-00602_11\n",
      "Generating Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suraj\\AppData\\Local\\Temp\\3\\ipykernel_5616\\2082810151.py:37: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize(inter_dim, Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Patches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:25<00:00,  1.47it/s]\n",
      "100%|██████████| 52/52 [00:37<00:00,  1.40it/s]\n",
      "100%|██████████| 38/38 [00:26<00:00,  1.45it/s]\n",
      "100%|██████████| 52/52 [00:36<00:00,  1.41it/s]\n",
      "100%|██████████| 38/38 [00:27<00:00,  1.39it/s]\n",
      "100%|██████████| 52/52 [00:35<00:00,  1.47it/s]\n",
      "100%|██████████| 38/38 [00:25<00:00,  1.48it/s]\n",
      "100%|██████████| 52/52 [00:37<00:00,  1.38it/s]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.46it/s]\n",
      "100%|██████████| 93/93 [01:07<00:00,  1.39it/s]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.44it/s]\n",
      "100%|██████████| 93/93 [01:07<00:00,  1.38it/s]\n",
      "100%|██████████| 28/28 [00:21<00:00,  1.31it/s]\n",
      "100%|██████████| 93/93 [01:03<00:00,  1.46it/s]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.46it/s]\n",
      "100%|██████████| 93/93 [01:17<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Creating_patches()\n",
      "[WinError 267] The directory name is invalid: 'D:/MGMT research project/Test/Working_Data/MGMT_negative/inter_UPENN-GBM-00604_11_FLAIR_10_row_10_col_1.png/'\n",
      "Creating Pickle Files\n",
      "Reading Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324000/324000 [1:02:19<00:00, 86.65it/s] \n",
      "100%|██████████| 435600/435600 [1:23:10<00:00, 87.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data:  759600\n",
      "Initializing Features & Labels\n",
      "List Size:  759600 759600\n",
      "Converting to Array\n",
      "Array Size with Reshape:  759600 759600\n",
      "Length of data:  759600 759600\n",
      "Plotting AUC-ROC Curve\n",
      "23738/23738 [==============================] - 380s 16ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[39m=\u001b[39m Load_Model()\n\u001b[0;32m     19\u001b[0m \u001b[39m# Plotting the AUC-ROC curve\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m Plotting_AUC_ROC_Curve(X,y,model)\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mPlotting_AUC_ROC_Curve\u001b[1;34m(X, y, model)\u001b[0m\n\u001b[0;32m     17\u001b[0m plt\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlower right\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mauc_roc_curve.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:445\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    444\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 445\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39mshow(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py:3616\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3614\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3615\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m-> 3616\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:523\u001b[0m, in \u001b[0;36mFigureManagerTk.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    521\u001b[0m manager_class\u001b[39m.\u001b[39m_owns_mainloop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m     first_manager\u001b[39m.\u001b[39;49mwindow\u001b[39m.\u001b[39;49mmainloop()\n\u001b[0;32m    524\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    525\u001b[0m     manager_class\u001b[39m.\u001b[39m_owns_mainloop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmainloop\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m     \u001b[39m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtk\u001b[39m.\u001b[39;49mmainloop(n)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main cell to execute the functions\n",
    "# # Reconstruction of folders\n",
    "# Reconstruct()\n",
    "\n",
    "# Test file creation for computation on independant cohort\n",
    "Test_file_creation()\n",
    "\n",
    "# Loading data\n",
    "X, y = Load_Data()\n",
    "\n",
    "# # Print lenght of data\n",
    "print('Length of data: ', len(X), len(y))\n",
    "\n",
    "results = []\n",
    "\n",
    "# Load model\n",
    "model = Load_Model()\n",
    "\n",
    "# Plotting the AUC-ROC curve\n",
    "Plotting_AUC_ROC_Curve(X,y,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
