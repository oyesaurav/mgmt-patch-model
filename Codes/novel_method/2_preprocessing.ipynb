{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/miniforge3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#  Import libraries and define variables\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")  # Adds the parent directory to sys.path\n",
    "import config \n",
    "\n",
    "# Define the modalities and classifications\n",
    "modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "classifications = ['MGMT_positive', 'MGMT_negative']\n",
    "\n",
    "# Define patch size and stride\n",
    "block_h, block_w = (32, 32)\n",
    "stride = 2\n",
    "\n",
    "# Interpolated image dimestions\n",
    "inter_dim = (110, 90)\n",
    "\n",
    "# Define paths to the BraTS dataset folders\n",
    "path = config.MAIN_DIR\n",
    "\n",
    "PATH = path + 'Data/'\n",
    "Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions --> For reading images and appending it to a list\n",
    "\n",
    "def read_image(data):\n",
    "    print('Reading Images')\n",
    "    class_num = 0\n",
    "    workdir = os.listdir(Work_Dir)\n",
    "    if '.DS_Store' in workdir:\n",
    "          workdir.remove('.DS_Store')\n",
    "          print('Removed .DS_Store')\n",
    "    for classi in classifications:\n",
    "        if classi in workdir:\n",
    "            workdir.remove(classi)\n",
    "    for pool in workdir:\n",
    "        pool_dir = Work_Dir + pool + '/'\n",
    "        pool_dir_list = os.listdir(pool_dir)\n",
    "        if '.DS_Store' in pool_dir_list:\n",
    "            pool_dir_list.remove('.DS_Store')\n",
    "            print('Removed .DS_Store')\n",
    "        for img in tqdm(pool_dir_list):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(pool_dir, img), cv2.IMREAD_GRAYSCALE)\n",
    "                # Saving images in the list\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        class_num = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions --> Initialize the feature & labels of the processes image in the list X & Y\n",
    "\n",
    "def Initializing_feature_labels(data, X, Y):\n",
    "    print('Initializing Features & Labels')\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        Y.append(label)\n",
    "    print('List Size: ', len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Reshape the list to numpy array\n",
    "\n",
    "def Converting(block_h, block_w, X, Y):\n",
    "    print('Converting to Array')\n",
    "    global x, y\n",
    "\n",
    "    # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    x = np.array(X).reshape((-1, block_h, block_w, 1))\n",
    "    y = np.array(Y)\n",
    "\n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Images\n",
      "Removed .DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1015200/1015200 [03:13<00:00, 5242.02it/s]\n",
      "100%|██████████| 1123200/1123200 [03:34<00:00, 5228.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data:  2138400\n",
      "Initializing Features & Labels\n",
      "List Size:  2138400 2138400\n",
      "Converting to Array\n",
      "Array Size with Reshape:  2138400 2138400\n",
      "Array Shape with Reshape:  (2138400, 32, 32, 1) (2138400,)\n"
     ]
    }
   ],
   "source": [
    "# Main cell to execute all the functions\n",
    "\n",
    "# Creating list for storing processed data\n",
    "data = []\n",
    "\n",
    "# Reading Images\n",
    "read_image(data) \n",
    "\n",
    "#  Printing the length of the data\n",
    "print('Size of the data: ', len(data))\n",
    "\n",
    "# Initializing all features & labels of the processed image in the list X & Y\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Initializing the features and labels\n",
    "Initializing_feature_labels(data, X, Y)\n",
    "\n",
    "# Converting the list into numpy array\n",
    "Converting(block_h, block_w, X, Y)\n",
    "\n",
    "# Storing the numpy array in a pickle file\n",
    "Storing_Preprocessed_Data = open(Work_Dir + 'X.pickle', 'wb')\n",
    "pickle.dump(X, Storing_Preprocessed_Data)\n",
    "Storing_Preprocessed_Data.close()\n",
    "\n",
    "Storing_Preprocessed_Data = open(Work_Dir + 'y.pickle', 'wb')\n",
    "pickle.dump(y, Storing_Preprocessed_Data)\n",
    "Storing_Preprocessed_Data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    modality_in_annotated = sorted(os.listdir(Work_Dir))\n",
    "\n",
    "    image=[]\n",
    "    label=[]\n",
    "\n",
    "    for classi in classifications:\n",
    "        if classi in modality_in_annotated:\n",
    "            modality_in_annotated.remove(classi)\n",
    "                \n",
    "    for pool_modality in modality_in_annotated:\n",
    "        for img in tqdm(os.listdir(Work_Dir + pool_modality + '/')):\n",
    "            image.append(Work_Dir + pool_modality + '/' + img)\n",
    "            label.append(0 if 'MGMT_negative' in pool_modality else 1) \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['images']=[str(x) for x in image]\n",
    "    df['labels']=[str(x) for x in label]\n",
    "    # df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "    df.to_csv('step2_file_paths.csv')\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
