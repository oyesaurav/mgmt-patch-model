{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import libraries and define variables\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "# import nibabel as nib\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Flatten, Dropout, LeakyReLU, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the modalities and classifications\n",
    "# modalities = ['t1', 't1gd', 't2', 'flair']\n",
    "# classifications = ['MGMT_positive', 'MGMT_negative']\n",
    "classifications = ['benign', 'malignant']\n",
    "\n",
    "# Define patch size and stride\n",
    "block_h, block_w = (64, 64)\n",
    "stride = 2\n",
    "\n",
    "# Interpolated image dimestions\n",
    "inter_dim = (110, 90)\n",
    "\n",
    "# Define epoch\n",
    "epoch = 10\n",
    "\n",
    "# Define paths to the BraTS dataset folders\n",
    "path = 'F:/gliobastoma-mgmt-upenn/'\n",
    "\n",
    "# PATH = path + 'Data/Working_Data'\n",
    "# Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "Work_Dir = path + 'Data/Skin Cancer/Working_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Load the data\n",
    "\n",
    "def load_data():\n",
    "    print('Loading data...')\n",
    "    pickle_in = open(Work_Dir + 'X.pickle', 'rb')\n",
    "    X = pickle.load(pickle_in) # Loading Features\n",
    "\n",
    "    pickle_in = open(Work_Dir + 'y.pickle', 'rb')\n",
    "    y = pickle.load(pickle_in) # Loading Labels \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Funtion Defination --> Model defination\n",
    "def Model(img_h, img_w, X_train, y_train, X_test, y_test, epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',kernel_initializer='he_normal',\n",
    "              input_shape=(img_h, img_w, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    # Pool_size is the size of filter.\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(48, (3, 3), padding='same',kernel_initializer='he_normal',))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(48, (3, 3), padding='same',kernel_initializer='he_normal',))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Flatten())  # Convert 3D feature map to 1D feature vector.\n",
    "\n",
    "    model.add(Dense(1096))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    model.optimizer.learning_rate = 0.0001\n",
    "\n",
    "    # Training the model & storing its detail in the variable h\n",
    "    history = model.fit(X_train, to_categorical(y_train,num_classes=2), batch_size=128, epochs=epoch, verbose=2,\n",
    "                        validation_data=(X_test, to_categorical(y_test)), shuffle=True)\n",
    "\n",
    "    # Evaluating performance of the Model\n",
    "    test_loss, test_acc = model.evaluate(X_test, to_categorical(y_test))\n",
    "    results.append(test_acc)\n",
    "    print('Test Loss is: ', test_loss, '\\nTest Accuracy is: ', test_acc)\n",
    "\n",
    "    # Saving the model in hierarchical Data Formate (HDF)\n",
    "    model.save(path + 'Outputs/latest_model'+'.h5')\n",
    "\n",
    "    return history, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Saving Validation Accuracy in the file\n",
    "\n",
    "def Saving_Test_Accuracy():\n",
    "    import numpy as np\n",
    "\n",
    "    print('Saving Test Accuracy...')\n",
    "\n",
    "    file = open(Result_File, \"a\")\n",
    "    file.write(case)\n",
    "    file.write(':\\n======')\n",
    "    file.write('\\nAll Test Accuracy:\\t')\n",
    "\n",
    "    for ans in results:\n",
    "        file.write(str(ans) + ', ')\n",
    "\n",
    "    file.write('\\nMean Test Accuracy:\\t' + str(np.mean(results)))\n",
    "    file.write('\\nMin Test Accuracy:\\t' + str(np.min(results)))\n",
    "    file.write('\\nMax Test Accuracy:\\t' + str(np.max(results)))\n",
    "    file.write('\\n\\n\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[134, 138, 143, ..., 162, 161, 161],\n",
       "        [131, 136, 141, ..., 162, 164, 167],\n",
       "        [129, 134, 139, ..., 160, 165, 171],\n",
       "        ...,\n",
       "        [ 60,  69,  83, ..., 158, 157, 160],\n",
       "        [ 53,  62,  75, ..., 160, 161, 159],\n",
       "        [ 48,  57,  69, ..., 163, 165, 161]],\n",
       "\n",
       "       [[152, 153, 154, ..., 166, 162, 160],\n",
       "        [153, 155, 157, ..., 165, 161, 159],\n",
       "        [153, 156, 160, ..., 162, 159, 156],\n",
       "        ...,\n",
       "        [148, 149, 151, ..., 150, 145, 141],\n",
       "        [144, 146, 149, ..., 152, 147, 144],\n",
       "        [142, 145, 148, ..., 155, 151, 148]],\n",
       "\n",
       "       [[155, 155, 155, ..., 157, 154, 154],\n",
       "        [159, 158, 157, ..., 155, 153, 153],\n",
       "        [161, 161, 159, ..., 153, 153, 155],\n",
       "        ...,\n",
       "        [153, 155, 157, ..., 142, 147, 152],\n",
       "        [151, 154, 156, ..., 143, 145, 149],\n",
       "        [148, 151, 154, ..., 147, 147, 148]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[159, 162, 166, ..., 176, 176, 176],\n",
       "        [159, 162, 166, ..., 177, 178, 178],\n",
       "        [159, 162, 165, ..., 178, 179, 180],\n",
       "        ...,\n",
       "        [141, 139, 139, ..., 173, 173, 173],\n",
       "        [112, 121, 133, ..., 172, 171, 170],\n",
       "        [115, 132, 151, ..., 172, 170, 168]],\n",
       "\n",
       "       [[166, 166, 166, ..., 176, 174, 173],\n",
       "        [167, 166, 166, ..., 177, 176, 175],\n",
       "        [167, 167, 166, ..., 179, 178, 176],\n",
       "        ...,\n",
       "        [137, 142, 149, ..., 173, 168, 164],\n",
       "        [141, 145, 150, ..., 170, 163, 158],\n",
       "        [153, 154, 155, ..., 167, 160, 154]],\n",
       "\n",
       "       [[165, 164, 163, ..., 172, 170, 168],\n",
       "        [164, 164, 163, ..., 174, 171, 170],\n",
       "        [164, 164, 163, ..., 175, 173, 172],\n",
       "        ...,\n",
       "        [153, 155, 156, ..., 164, 161, 160],\n",
       "        [152, 154, 156, ..., 159, 158, 158],\n",
       "        [151, 153, 156, ..., 156, 155, 157]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main cell to execute the functions\n",
    "\n",
    "X, y = load_data()\n",
    "y=np.array(y)\n",
    "X=np.array(X)\n",
    "# print(X[0].shape)\n",
    "results = []\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Training the model\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[134, 138, 143, ..., 162, 161, 161],\n",
       "        [131, 136, 141, ..., 162, 164, 167],\n",
       "        [129, 134, 139, ..., 160, 165, 171],\n",
       "        ...,\n",
       "        [ 60,  69,  83, ..., 158, 157, 160],\n",
       "        [ 53,  62,  75, ..., 160, 161, 159],\n",
       "        [ 48,  57,  69, ..., 163, 165, 161]],\n",
       "\n",
       "       [[152, 153, 154, ..., 166, 162, 160],\n",
       "        [153, 155, 157, ..., 165, 161, 159],\n",
       "        [153, 156, 160, ..., 162, 159, 156],\n",
       "        ...,\n",
       "        [148, 149, 151, ..., 150, 145, 141],\n",
       "        [144, 146, 149, ..., 152, 147, 144],\n",
       "        [142, 145, 148, ..., 155, 151, 148]],\n",
       "\n",
       "       [[155, 155, 155, ..., 157, 154, 154],\n",
       "        [159, 158, 157, ..., 155, 153, 153],\n",
       "        [161, 161, 159, ..., 153, 153, 155],\n",
       "        ...,\n",
       "        [153, 155, 157, ..., 142, 147, 152],\n",
       "        [151, 154, 156, ..., 143, 145, 149],\n",
       "        [148, 151, 154, ..., 147, 147, 148]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[159, 162, 166, ..., 176, 176, 176],\n",
       "        [159, 162, 166, ..., 177, 178, 178],\n",
       "        [159, 162, 165, ..., 178, 179, 180],\n",
       "        ...,\n",
       "        [141, 139, 139, ..., 173, 173, 173],\n",
       "        [112, 121, 133, ..., 172, 171, 170],\n",
       "        [115, 132, 151, ..., 172, 170, 168]],\n",
       "\n",
       "       [[166, 166, 166, ..., 176, 174, 173],\n",
       "        [167, 166, 166, ..., 177, 176, 175],\n",
       "        [167, 167, 166, ..., 179, 178, 176],\n",
       "        ...,\n",
       "        [137, 142, 149, ..., 173, 168, 164],\n",
       "        [141, 145, 150, ..., 170, 163, 158],\n",
       "        [153, 154, 155, ..., 167, 160, 154]],\n",
       "\n",
       "       [[165, 164, 163, ..., 172, 170, 168],\n",
       "        [164, 164, 163, ..., 174, 171, 170],\n",
       "        [164, 164, 163, ..., 175, 173, 172],\n",
       "        ...,\n",
       "        [153, 155, 156, ..., 164, 161, 160],\n",
       "        [152, 154, 156, ..., 159, 158, 158],\n",
       "        [151, 153, 156, ..., 156, 155, 157]]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13171, 64, 64)\n",
      "(13171,)\n",
      "(5645, 64, 64)\n",
      "(5645,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/103 - 43s - loss: 25.4335 - accuracy: 0.5264 - val_loss: 2.8575 - val_accuracy: 0.6243 - 43s/epoch - 419ms/step\n",
      "Epoch 2/10\n",
      "103/103 - 45s - loss: 7.4500 - accuracy: 0.5460 - val_loss: 2.4695 - val_accuracy: 0.5095 - 45s/epoch - 441ms/step\n",
      "Epoch 3/10\n",
      "103/103 - 47s - loss: 3.3289 - accuracy: 0.5413 - val_loss: 0.6916 - val_accuracy: 0.6512 - 47s/epoch - 460ms/step\n",
      "Epoch 4/10\n",
      "103/103 - 47s - loss: 1.8930 - accuracy: 0.5579 - val_loss: 0.8085 - val_accuracy: 0.6728 - 47s/epoch - 458ms/step\n",
      "Epoch 5/10\n",
      "103/103 - 46s - loss: 1.4215 - accuracy: 0.5718 - val_loss: 0.6905 - val_accuracy: 0.6034 - 46s/epoch - 451ms/step\n",
      "Epoch 6/10\n",
      "103/103 - 47s - loss: 1.2538 - accuracy: 0.5614 - val_loss: 0.6675 - val_accuracy: 0.6117 - 47s/epoch - 456ms/step\n",
      "Epoch 7/10\n",
      "103/103 - 49s - loss: 1.1226 - accuracy: 0.5635 - val_loss: 0.7065 - val_accuracy: 0.5979 - 49s/epoch - 477ms/step\n",
      "Epoch 8/10\n",
      "103/103 - 46s - loss: 1.0390 - accuracy: 0.5637 - val_loss: 0.6247 - val_accuracy: 0.6717 - 46s/epoch - 447ms/step\n",
      "Epoch 9/10\n",
      "103/103 - 46s - loss: 0.9597 - accuracy: 0.5730 - val_loss: 0.6261 - val_accuracy: 0.6702 - 46s/epoch - 451ms/step\n",
      "Epoch 10/10\n",
      "103/103 - 46s - loss: 0.9163 - accuracy: 0.5745 - val_loss: 0.6177 - val_accuracy: 0.6787 - 46s/epoch - 449ms/step\n",
      "177/177 [==============================] - 8s 43ms/step - loss: 0.6177 - accuracy: 0.6787\n",
      "Test Loss is:  0.6176560521125793 \n",
      "Test Accuracy is:  0.6786536574363708\n"
     ]
    }
   ],
   "source": [
    "history, model = Model(block_h, block_w, X_train, y_train, X_test, y_test, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
