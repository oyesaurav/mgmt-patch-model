{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import libraries and define variables\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import cv2 as cv\n",
    "import random as rn\n",
    "from multiprocessing import Pool,Process\n",
    "import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Flatten, Dropout, LeakyReLU, Activation, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from keras.layers.convolutional import Conv2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import TruePositives,TrueNegatives,FalsePositives,FalseNegatives,AUC,Recall,Precision\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "# # Define the modalities and classifications\n",
    "# modalities = ['T1']\n",
    "# classifications = ['MGMT_positive', 'MGMT_negative']\n",
    "\n",
    "# # Define patch size and stride\n",
    "# block_h, block_w = config.PATCH_SIZE\n",
    "# stride = 2\n",
    "\n",
    "# # Interpolated image dimestions\n",
    "# inter_dim = (110, 90)\n",
    "\n",
    "# # Define epoch\n",
    "# epoch = 100\n",
    "# batch_size = 16\n",
    "\n",
    "# # Define paths to the BraTS dataset folders\n",
    "# path = config.MAIN_DIR\n",
    "\n",
    "# PATH = config.MAIN_DIR + 'Data/'\n",
    "# Org_Dir = PATH + 'Original_Data_Backup/'\n",
    "# Work_Dir = PATH + 'Working_Data/'\n",
    "# Preprocess_Dir = path + 'Preprocessed/layers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_id =  os.listdir(r'D:\\mgmt-patch-model\\Data\\Working_Data\\MGMT_negative\\T1')\n",
    "pos_id = os.listdir(r'D:\\mgmt-patch-model\\Data\\Working_Data\\MGMT_positive\\T1')\n",
    "\n",
    "for i in range(len(neg_id)):\n",
    "    neg_id[i] = 'D:/mgmt-patch-model/Data/Working_Data/MGMT_negative/T1/' +neg_id[i]\n",
    "for i in range(len(pos_id)):\n",
    "    pos_id[i] = 'D:/mgmt-patch-model/Data/Working_Data/MGMT_positive/T1/' +pos_id[i]\n",
    "\n",
    "train_neg_id = neg_id[:60]\n",
    "val_neg_id = neg_id[60:]\n",
    "\n",
    "train_pos_id = pos_id[:60]\n",
    "val_pos_id = pos_id[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(lst,l):\n",
    "    label = []\n",
    "    train_x = []\n",
    "    for pat in tqdm(lst):\n",
    "        for img_id in os.listdir(pat):\n",
    "            img = cv.imread(os.path.join(pat,img_id),cv.IMREAD_GRAYSCALE)\n",
    "            if img.shape[0]<30 or img.shape[1]<30: continue\n",
    "\n",
    "            img = cv.resize(img,(64,64))\n",
    "            train_x.append(img)\n",
    "            label.append(l)\n",
    "\n",
    "    return train_x, label\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 25.44it/s]\n",
      "100%|██████████| 60/60 [00:02<00:00, 23.78it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 31.18it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 29.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pos_x, train_pos_y= X(train_pos_id,1)\n",
    "train_neg_x, train_neg_y= X(train_neg_id,0)\n",
    "\n",
    "train_x = train_pos_x + train_neg_x\n",
    "train_y = train_pos_y + train_neg_y\n",
    "\n",
    "val_pos_x, val_pos_y= X(val_pos_id,1)\n",
    "val_neg_x, val_neg_y= X(val_neg_id,0)\n",
    "\n",
    "val_x = val_pos_x + val_neg_x\n",
    "val_y = val_pos_y + val_neg_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model () :\n",
    "        model = Sequential()\n",
    "\n",
    "        # model.add(Conv2D(16, (5,5), padding='same',input_shape=(90,110,1),kernel_initializer=HeNormal()))\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(8, (5, 5), padding='same',input_shape=(64,64,1),kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01)))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        # model.add(Conv2D(8, (3, 3), padding='same',kernel_initializer=HeNormal()))\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.))\n",
    "\n",
    "        model.add(Conv2D(4, (3, 3), padding='same',kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01)))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.1))\n",
    "        \n",
    "        model.add(Conv2D(4, (3, 3), padding='same',kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01)))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "        # model.add(Conv2D(48, (3, 3), padding='same'))\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        # model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Flatten())  # Convert 3D feature map to 1D feature vector.\n",
    "\n",
    "        # model.add(Dense(10,kernel_initializer=HeNormal()))\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.3))\n",
    "\n",
    "        # model.add(Dense(10,kernel_initializer=HeNormal()))\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.2))\n",
    "        \n",
    "        # model.add(Dense(10,kernel_initializer=HeNormal()))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Dense(10,kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        # model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy',TruePositives(),\n",
    "                             TrueNegatives(),FalsePositives(),\n",
    "                             FalseNegatives(),AUC(),Recall(),Precision()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 20s 31ms/step - loss: 1.0053 - accuracy: 0.5915 - true_positives_7: 1468.0000 - true_negatives_7: 1298.0000 - false_positives_7: 1066.0000 - false_negatives_7: 844.0000 - auc_7: 0.6292 - recall_7: 0.6349 - precision_7: 0.5793 - val_loss: 0.9276 - val_accuracy: 0.4876 - val_true_positives_7: 349.0000 - val_true_negatives_7: 201.0000 - val_false_positives_7: 356.0000 - val_false_negatives_7: 222.0000 - val_auc_7: 0.4557 - val_recall_7: 0.6112 - val_precision_7: 0.4950\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 17s 29ms/step - loss: 0.7689 - accuracy: 0.6730 - true_positives_7: 1523.0000 - true_negatives_7: 1624.0000 - false_positives_7: 740.0000 - false_negatives_7: 789.0000 - auc_7: 0.7399 - recall_7: 0.6587 - precision_7: 0.6730 - val_loss: 0.9482 - val_accuracy: 0.4734 - val_true_positives_7: 90.0000 - val_true_negatives_7: 444.0000 - val_false_positives_7: 113.0000 - val_false_negatives_7: 481.0000 - val_auc_7: 0.4505 - val_recall_7: 0.1576 - val_precision_7: 0.4433\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 18s 30ms/step - loss: 0.6912 - accuracy: 0.7102 - true_positives_7: 1591.0000 - true_negatives_7: 1730.0000 - false_positives_7: 634.0000 - false_negatives_7: 721.0000 - auc_7: 0.7880 - recall_7: 0.6881 - precision_7: 0.7151 - val_loss: 1.1338 - val_accuracy: 0.4610 - val_true_positives_7: 467.0000 - val_true_negatives_7: 53.0000 - val_false_positives_7: 504.0000 - val_false_negatives_7: 104.0000 - val_auc_7: 0.4641 - val_recall_7: 0.8179 - val_precision_7: 0.4809\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 18s 31ms/step - loss: 0.6693 - accuracy: 0.7408 - true_positives_7: 1704.0000 - true_negatives_7: 1760.0000 - false_positives_7: 604.0000 - false_negatives_7: 608.0000 - auc_7: 0.8115 - recall_7: 0.7370 - precision_7: 0.7383 - val_loss: 1.2069 - val_accuracy: 0.4929 - val_true_positives_7: 13.0000 - val_true_negatives_7: 543.0000 - val_false_positives_7: 14.0000 - val_false_negatives_7: 558.0000 - val_auc_7: 0.4911 - val_recall_7: 0.0228 - val_precision_7: 0.4815\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 18s 31ms/step - loss: 0.6557 - accuracy: 0.7521 - true_positives_7: 1716.0000 - true_negatives_7: 1801.0000 - false_positives_7: 563.0000 - false_negatives_7: 596.0000 - auc_7: 0.8249 - recall_7: 0.7422 - precision_7: 0.7530 - val_loss: 1.0362 - val_accuracy: 0.5284 - val_true_positives_7: 269.0000 - val_true_negatives_7: 327.0000 - val_false_positives_7: 230.0000 - val_false_negatives_7: 302.0000 - val_auc_7: 0.5519 - val_recall_7: 0.4711 - val_precision_7: 0.5391\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 16s 27ms/step - loss: 0.6376 - accuracy: 0.7613 - true_positives_7: 1767.0000 - true_negatives_7: 1793.0000 - false_positives_7: 571.0000 - false_negatives_7: 545.0000 - auc_7: 0.8417 - recall_7: 0.7643 - precision_7: 0.7558 - val_loss: 1.0389 - val_accuracy: 0.5523 - val_true_positives_7: 244.0000 - val_true_negatives_7: 379.0000 - val_false_positives_7: 178.0000 - val_false_negatives_7: 327.0000 - val_auc_7: 0.5607 - val_recall_7: 0.4273 - val_precision_7: 0.5782\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 16s 28ms/step - loss: 0.6375 - accuracy: 0.7703 - true_positives_7: 1776.0000 - true_negatives_7: 1826.0000 - false_positives_7: 538.0000 - false_negatives_7: 536.0000 - auc_7: 0.8445 - recall_7: 0.7682 - precision_7: 0.7675 - val_loss: 1.0908 - val_accuracy: 0.4770 - val_true_positives_7: 192.0000 - val_true_negatives_7: 346.0000 - val_false_positives_7: 211.0000 - val_false_negatives_7: 379.0000 - val_auc_7: 0.4876 - val_recall_7: 0.3363 - val_precision_7: 0.4764\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 16s 28ms/step - loss: 0.6210 - accuracy: 0.7797 - true_positives_7: 1809.0000 - true_negatives_7: 1837.0000 - false_positives_7: 527.0000 - false_negatives_7: 503.0000 - auc_7: 0.8608 - recall_7: 0.7824 - precision_7: 0.7744 - val_loss: 1.2219 - val_accuracy: 0.5222 - val_true_positives_7: 222.0000 - val_true_negatives_7: 367.0000 - val_false_positives_7: 190.0000 - val_false_negatives_7: 349.0000 - val_auc_7: 0.5206 - val_recall_7: 0.3888 - val_precision_7: 0.5388\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 17s 28ms/step - loss: 0.6085 - accuracy: 0.7900 - true_positives_7: 1819.0000 - true_negatives_7: 1875.0000 - false_positives_7: 489.0000 - false_negatives_7: 493.0000 - auc_7: 0.8683 - recall_7: 0.7868 - precision_7: 0.7881 - val_loss: 1.3165 - val_accuracy: 0.4672 - val_true_positives_7: 335.0000 - val_true_negatives_7: 192.0000 - val_false_positives_7: 365.0000 - val_false_negatives_7: 236.0000 - val_auc_7: 0.4586 - val_recall_7: 0.5867 - val_precision_7: 0.4786\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 17s 29ms/step - loss: 0.6016 - accuracy: 0.7908 - true_positives_7: 1831.0000 - true_negatives_7: 1867.0000 - false_positives_7: 497.0000 - false_negatives_7: 481.0000 - auc_7: 0.8750 - recall_7: 0.7920 - precision_7: 0.7865 - val_loss: 1.2001 - val_accuracy: 0.4796 - val_true_positives_7: 231.0000 - val_true_negatives_7: 310.0000 - val_false_positives_7: 247.0000 - val_false_negatives_7: 340.0000 - val_auc_7: 0.4444 - val_recall_7: 0.4046 - val_precision_7: 0.4833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc52b8b820>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(train_x),np.array(train_y), \n",
    "          validation_data=(np.array(val_x),np.array(val_y)),\n",
    "          batch_size= 8,\n",
    "          epochs = 10,\n",
    "          shuffle= True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
