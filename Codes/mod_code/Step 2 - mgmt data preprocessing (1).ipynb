{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136633d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d15bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7724eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For reading the Images and append it to a list\n",
    "\n",
    "def Reading_Data():\n",
    "    from tqdm import tqdm  # It is a progress bar, Used to track the estimated remaining time.\n",
    "    import cv2  # Used for Images processing.\n",
    "    print(\"Reading Data\")\n",
    "    splitpath = os.listdir(Split_Path)\n",
    "    if '.DS_Store' in splitpath:\n",
    "        splitpath.remove('.DS_Store')\n",
    "    for category in splitpath:\n",
    "        Category_Path = os.path.join(Split_Path, category + '/')  # Joining path for \"MGMT_positive & MGMT_negative\".\n",
    "        print(Category_Path)\n",
    "        class_num = os.listdir(Split_Path).index(category)  # Initializing index for each class.\n",
    "        print(class_num)\n",
    "        categorypath = os.listdir(Category_Path)\n",
    "        if '.DS_Store' in categorypath:\n",
    "            categorypath.remove('.DS_Store')\n",
    "        for img_folder in tqdm(categorypath):  # Working with the folders of images\n",
    "            Img_Path = os.path.join(Category_Path, img_folder + '/')\n",
    "\n",
    "            for img in os.listdir(Img_Path):  # listing all images present in the image folder.\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(Img_Path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                    training_data.append([img_array, class_num])  # Saving images with their corresponding class labels.\n",
    "                except Exception as e:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a02cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "\n",
    "def Initilizing_Features_Labels():\n",
    "    print(\"Initilizing Features & Labels\")\n",
    "    for features, label in training_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    print('List Size: ', len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4afa161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defination --> Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "\n",
    "def Converting(block_h, block_w):\n",
    "    import numpy as np  # Used for array operations.\n",
    "    global X, y\n",
    "    print(\"Converting into Numpy Array\")\n",
    "    \n",
    "    X = np.array(X).reshape(-1, block_h, block_w, 1)  # -1 is added to solve dimension mismatch while converting list to an array.\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print('Array Size with Reshape: ', len(X), len(y))\n",
    "    print('Array Shape with Reshape: ', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bf7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition --> For Storing Preprocessed data in the file.\n",
    "\n",
    "def Storing_Preprocessed_data():\n",
    "    import pickle  # To save the data or Trained Deep learning model in the File.\n",
    "    print(\"Storing Preprocessed Data\")\n",
    "    # Storing Training Features & Labels\n",
    "    pickle_out = open(Split_Path + '/X.pickle', 'wb')\n",
    "    pickle.dump(X, pickle_out)  # Storing Training Features\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(Split_Path + '/y.pickle', 'wb')\n",
    "    pickle.dump(y, pickle_out)  # Storing Training Labels\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1450e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_5/train/MGMT_positive/\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9468/9468 [01:32<00:00, 102.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_5/train/MGMT_negative/\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9202/9202 [01:39<00:00, 92.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case_5\n",
      "Length of the total training data: 1529474\n",
      "1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 Initilizing Features & Labels\n",
      "List Size:  1529474 1529474\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  1529474 1529474\n",
      "Array Shape with Reshape:  (1529474, 32, 32, 1) (1529474,)\n",
      "Storing Preprocessed Data\n",
      "\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_2/train/MGMT_positive/\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9393/9393 [01:40<00:00, 93.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_2/train/MGMT_negative/\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9200/9200 [01:42<00:00, 89.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case_2\n",
      "Length of the total training data: 1568349\n",
      "1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 Initilizing Features & Labels\n",
      "List Size:  1568349 1568349\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  1568349 1568349\n",
      "Array Shape with Reshape:  (1568349, 32, 32, 1) (1568349,)\n",
      "Storing Preprocessed Data\n",
      "\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_3/train/MGMT_positive/\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9527/9527 [01:41<00:00, 93.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_3/train/MGMT_negative/\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9167/9167 [01:40<00:00, 90.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case_3\n",
      "Length of the total training data: 1548874\n",
      "0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 Initilizing Features & Labels\n",
      "List Size:  1548874 1548874\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  1548874 1548874\n",
      "Array Shape with Reshape:  (1548874, 32, 32, 1) (1548874,)\n",
      "Storing Preprocessed Data\n",
      "\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_4/train/MGMT_positive/\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9438/9438 [01:37<00:00, 96.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_4/train/MGMT_negative/\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9178/9178 [01:42<00:00, 89.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case_4\n",
      "Length of the total training data: 1555094\n",
      "1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 Initilizing Features & Labels\n",
      "List Size:  1555094 1555094\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  1555094 1555094\n",
      "Array Shape with Reshape:  (1555094, 32, 32, 1) (1555094,)\n",
      "Storing Preprocessed Data\n",
      "\n",
      "Reading Data\n",
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_1/train/MGMT_positive/\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9507/9507 [01:37<00:00, 97.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data/Working_Data/Case_1/train/MGMT_negative/\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9425/9425 [01:46<00:00, 88.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case_1\n",
      "Length of the total training data: 1581173\n",
      "1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 Initilizing Features & Labels\n",
      "List Size:  1581173 1581173\n",
      "Converting into Numpy Array\n",
      "Array Size with Reshape:  1581173 1581173\n",
      "Array Shape with Reshape:  (1581173, 32, 32, 1) (1581173,)\n",
      "Storing Preprocessed Data\n",
      "\n",
      "Done..!!\n"
     ]
    }
   ],
   "source": [
    "# All Function Calls\n",
    "import os\n",
    "import random\n",
    "import numpy as np  # Used for array operations.\n",
    "import pickle\n",
    "\n",
    "PATH = path + 'Data/BRATS/mod_data/'\n",
    "Work_Dir = PATH + 'Working_Data/'\n",
    "workdir = os.listdir(Work_Dir)\n",
    "if '.DS_Store' in workdir:\n",
    "    workdir.remove('.DS_Store')\n",
    "# Calling Functions:\n",
    "for case in workdir:\n",
    "    Case_Path = os.path.join(Work_Dir, case)  # Joining \"Cases\" path.\n",
    "\n",
    "    Split_Path = Case_Path + '/train/'  # Joining \"train\" folder with \"Cases\" path.\n",
    "\n",
    "    # Creating list for storing processed data\n",
    "    training_data = []\n",
    "\n",
    "    # Function Call --> For reading the Images and append it to a list\n",
    "    Reading_Data()\n",
    "\n",
    "    # Printing Length of the training data.\n",
    "    print(case)\n",
    "    print('Length of the total training data: ' + str(len(training_data)))\n",
    "\n",
    "    # Randomly Shuffling and printing data for unbiased model.\n",
    "    random.shuffle(training_data)\n",
    "    for sample in training_data[:50]:\n",
    "        print(sample[1], end=' ')\n",
    "\n",
    "    # Initilizing all features & labels of the processed image in the list X & Y.\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Function Call --> For Initilizing all features & labels of the processed image in the list X & Y\n",
    "    Initilizing_Features_Labels()\n",
    "    \n",
    "    # Function Call --> For Converting List into Numpy Array for faster calculation & it also take less space.\n",
    "    Converting(block_h, block_w)\n",
    "\n",
    "    # Function Call --> Storing Preprocessed data in the file.\n",
    "    Storing_Preprocessed_data()\n",
    "    print()\n",
    "\n",
    "os.chdir(PATH)\n",
    "print('Done..!!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
