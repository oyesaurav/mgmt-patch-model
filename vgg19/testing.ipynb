{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required Libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, recall_score, cohen_kappa_score, precision_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3  # InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2  # MobileNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet121  # DenseNet121\n",
    "from tensorflow.keras.applications.densenet import DenseNet169  # DenseNet169\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet  # MobileNet\n",
    "from tensorflow.keras.applications.xception import Xception  # Xception\n",
    "from tensorflow.keras.applications import ResNet101  # ResNet 101\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50  # ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import VGG19  # VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16  # VGG16\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier  # XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier  # AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier  # RandomForestClassifier\n",
    "from sklearn.svm import SVC  # SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNeighborsClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sn.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    '''\n",
    "        parameters\n",
    "        ----------\n",
    "        path : input path of the images\n",
    "        \n",
    "        returns\n",
    "        -------\n",
    "        loadedImages : list of loaded images \n",
    "    '''\n",
    "    from tqdm import tqdm\n",
    "    import cv2\n",
    "    sample = []\n",
    "    for filename in tqdm(glob.glob(path)):\n",
    "\n",
    "        img = cv2.imread(filename)\n",
    "        img = skimage.transform.resize(img, (224, 224, 3))\n",
    "        IMG = np.array(img)\n",
    "        sample.append(IMG)\n",
    "\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_1='/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/train/MGMT_negative/*.png'\n",
    "train_path_2 = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/train/MGMT_positive/*.png'\n",
    "\n",
    "test_path_1 = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/test/MGMT_negative/*.png'\n",
    "test_path_2 = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/Data/BRATS/mod_data1/Working_Data/Case_1/test/MGMT_positive/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4985/4985 [00:13<00:00, 370.65it/s]\n",
      "100%|██████████| 5368/5368 [00:13<00:00, 384.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_neg = loadImages(train_path_1)\n",
    "train_pos = loadImages(train_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:03<00:00, 374.94it/s]\n",
      "100%|██████████| 1287/1287 [00:03<00:00, 377.25it/s]\n"
     ]
    }
   ],
   "source": [
    "test_neg = loadImages(test_path_1)\n",
    "test_pos = loadImages(test_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_neg = pd.DataFrame({'images': train_neg, 'labels': 0})\n",
    "df_train_pos = pd.DataFrame({'images': train_pos, 'labels': 1})\n",
    "\n",
    "df_test_neg = pd.DataFrame({'images': test_neg, 'labels': 0})\n",
    "df_test_pos = pd.DataFrame({'images': test_pos, 'labels': 1})\n",
    "\n",
    "# deleting vriables to ensure memory is not full\n",
    "del train_neg, train_pos, test_neg, test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12804, 2)\n"
     ]
    }
   ],
   "source": [
    "final_data = [df_train_neg, df_train_pos, df_test_neg, df_test_pos]\n",
    "final_data = pd.concat(final_data)\n",
    "\n",
    "print(final_data.shape)\n",
    "\n",
    "# delete datframes to ensure memory is not full\n",
    "del df_train_neg, df_train_pos, df_test_neg, df_test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data['images']\n",
    "train_labels = final_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Count: Counter({1: 6655, 0: 6149})\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels Count:\",Counter(np.array(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "onehot = LabelEncoder()\n",
    "train_labels = onehot.fit_transform(train_labels)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 8962\n",
      "length y_train: 8962\n",
      "length X_test: 3842\n",
      "length y_test: 3842\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=train_labels,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print('length X_train:', len(X_train))\n",
    "print('length y_train:', len(y_train))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8962, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.empty(\n",
    "    (len(X_train), X_train[0].shape[0], X_train[0].shape[1], X_train[0].shape[2]))\n",
    "for i, x in enumerate(X_train):\n",
    "    x_train[i] = X_train[i]\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3842, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.empty(\n",
    "    (len(X_test), X_test[0].shape[0], X_test[0].shape[1], X_test[0].shape[2]))\n",
    "for i, x in enumerate(X_test):\n",
    "    x_test[i] = X_test[i]\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 17:21:04.956872: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-08 17:21:04.957581: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(include_top=True, weights='imagenet', input_shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 15:41:29.092909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 27s 96ms/step\n",
      "121/121 [==============================] - 11s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(x_train)\n",
    "test_features = model_feat.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8962, 4)\n",
      "(3842, 4)\n"
     ]
    }
   ],
   "source": [
    "# total features in the model\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features, y_train,\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  stratify=y_train,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 6273\n",
      "length y_train: 6273\n",
      "length X_val: 2689\n",
      "length y_val: 2689\n",
      "length X_test: 3842\n",
      "length y_test: 3842\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_features, y_test\n",
    "\n",
    "print('length X_train:', len(x_train_acc))\n",
    "print('length y_train:', len(y_train_acc))\n",
    "\n",
    "print('length X_val:',  len(x_val_acc))\n",
    "print('length y_val:', len(y_val_acc))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = sentiment_fit.predict(X_train)\n",
    "    y_pred_val = sentiment_fit.predict(X_val)\n",
    "    y_pred_test = sentiment_fit.predict(X_test)\n",
    "\n",
    "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train), 4)*100\n",
    "    train_precision = np.round(precision_score(\n",
    "        y_train, y_pred_train, average='weighted'), 4)\n",
    "    train_recall = np.round(recall_score(\n",
    "        y_train, y_pred_train, average='weighted'), 4)\n",
    "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'), 4)\n",
    "    train_kappa = np.round(cohen_kappa_score(y_train, y_pred_train), 4)\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val), 4)*100\n",
    "    val_precision = np.round(precision_score(\n",
    "        y_val, y_pred_val, average='weighted'), 4)\n",
    "    val_recall = np.round(recall_score(\n",
    "        y_val, y_pred_val, average='weighted'), 4)\n",
    "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'), 4)\n",
    "    val_kappa = np.round(cohen_kappa_score(y_val, y_pred_val), 4)\n",
    "    val_confusion_matrix = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test), 4)*100\n",
    "    test_precision = np.round(precision_score(\n",
    "        y_test, y_pred_test, average='weighted'), 4)\n",
    "    test_recall = np.round(recall_score(\n",
    "        y_test, y_pred_test, average='weighted'), 4)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'), 4)\n",
    "    test_kappa = np.round(cohen_kappa_score(y_test, y_pred_test), 4)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print('------------------------ Train Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(train_accuracy))\n",
    "    print(\"F1_score : {}\".format(train_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(train_kappa))\n",
    "    print(\"Recall : {}\".format(train_recall))\n",
    "    print(\"Precision : {}\".format(train_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(train_confusion_matrix))\n",
    "\n",
    "    print()\n",
    "    print('------------------------ Validation Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(val_accuracy))\n",
    "    print(\"F1_score : {}\".format(val_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(val_kappa))\n",
    "    print(\"Recall : {}\".format(val_recall))\n",
    "    print(\"Precision : {}\".format(val_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(val_confusion_matrix))\n",
    "\n",
    "    print()\n",
    "    print('------------------------ Test Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall : {}\".format(test_recall))\n",
    "    print(\"Precision : {}\".format(test_precision))\n",
    "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "        \"K Nearest Neighbour Classifier\",\n",
    "        'SVM',\n",
    "        \"Random Forest Classifier\",\n",
    "        \"AdaBoost Classifier\", \n",
    "        \"XGB Classifier\",\n",
    "         ]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "        ]\n",
    "\n",
    "zipped_clf = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print(\"Fitting {} on features \".format(n))\n",
    "        #print(c)\n",
    "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting K Nearest Neighbour Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 71.32%\n",
      "F1_score : 0.7129\n",
      "Cohen Kappa Score : 0.4247 \n",
      "Recall : 0.7132\n",
      "Precision : 0.7131\n",
      "Confusion Matrix :\n",
      " [[2054  959]\n",
      " [ 840 2420]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 56.120000000000005%\n",
      "F1_score : 0.5601\n",
      "Cohen Kappa Score : 0.1186 \n",
      "Recall : 0.5612\n",
      "Precision : 0.5603\n",
      "Confusion Matrix :\n",
      " [[656 635]\n",
      " [545 853]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 57.11000000000001%\n",
      "F1_score : 0.5703\n",
      "Cohen Kappa Score : 0.139 \n",
      "Recall : 0.5711\n",
      "Precision : 0.5703\n",
      "Confusion Matrix : [[ 970  875]\n",
      " [ 773 1224]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting SVM on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 59.209999999999994%\n",
      "F1_score : 0.5638\n",
      "Cohen Kappa Score : 0.1675 \n",
      "Recall : 0.5921\n",
      "Precision : 0.6091\n",
      "Confusion Matrix :\n",
      " [[ 999 2014]\n",
      " [ 545 2715]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 57.230000000000004%\n",
      "F1_score : 0.5443\n",
      "Cohen Kappa Score : 0.1275 \n",
      "Recall : 0.5723\n",
      "Precision : 0.5819\n",
      "Confusion Matrix :\n",
      " [[ 410  881]\n",
      " [ 269 1129]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 59.58%\n",
      "F1_score : 0.5678\n",
      "Cohen Kappa Score : 0.175 \n",
      "Recall : 0.5958\n",
      "Precision : 0.614\n",
      "Confusion Matrix : [[ 619 1226]\n",
      " [ 327 1670]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting Random Forest Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 99.22%\n",
      "F1_score : 0.9922\n",
      "Cohen Kappa Score : 0.9843 \n",
      "Recall : 0.9922\n",
      "Precision : 0.9923\n",
      "Confusion Matrix :\n",
      " [[2964   49]\n",
      " [   0 3260]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 57.269999999999996%\n",
      "F1_score : 0.5721\n",
      "Cohen Kappa Score : 0.1426 \n",
      "Recall : 0.5727\n",
      "Precision : 0.5721\n",
      "Confusion Matrix :\n",
      " [[688 603]\n",
      " [546 852]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 58.17%\n",
      "F1_score : 0.5813\n",
      "Cohen Kappa Score : 0.1609 \n",
      "Recall : 0.5817\n",
      "Precision : 0.5812\n",
      "Confusion Matrix : [[1005  840]\n",
      " [ 767 1230]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting AdaBoost Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 61.21%\n",
      "F1_score : 0.5992\n",
      "Cohen Kappa Score : 0.2131 \n",
      "Recall : 0.6121\n",
      "Precision : 0.6198\n",
      "Confusion Matrix :\n",
      " [[1294 1719]\n",
      " [ 714 2546]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 57.79%\n",
      "F1_score : 0.5624\n",
      "Cohen Kappa Score : 0.143 \n",
      "Recall : 0.5779\n",
      "Precision : 0.5816\n",
      "Confusion Matrix :\n",
      " [[ 497  794]\n",
      " [ 341 1057]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 59.84%\n",
      "F1_score : 0.5847\n",
      "Cohen Kappa Score : 0.185 \n",
      "Recall : 0.5984\n",
      "Precision : 0.6044\n",
      "Confusion Matrix : [[ 762 1083]\n",
      " [ 460 1537]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting XGB Classifier on features \n",
      "[15:43:05] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 86.74%\n",
      "F1_score : 0.8669\n",
      "Cohen Kappa Score : 0.7335 \n",
      "Recall : 0.8674\n",
      "Precision : 0.8693\n",
      "Confusion Matrix :\n",
      " [[2472  541]\n",
      " [ 291 2969]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 58.01%\n",
      "F1_score : 0.5777\n",
      "Cohen Kappa Score : 0.155 \n",
      "Recall : 0.5801\n",
      "Precision : 0.5793\n",
      "Confusion Matrix :\n",
      " [[647 644]\n",
      " [485 913]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 58.3%\n",
      "F1_score : 0.5813\n",
      "Cohen Kappa Score : 0.1616 \n",
      "Recall : 0.583\n",
      "Precision : 0.5822\n",
      "Confusion Matrix : [[ 952  893]\n",
      " [ 709 1288]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
