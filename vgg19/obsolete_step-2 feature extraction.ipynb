{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varialble definations\n",
    "path = '/Users/vitthal/Documents/Research/DataScience/MedicalResearch/mgmt/'\n",
    "block_h, block_w = (120,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "class ImageModel:\n",
    "    def __init__(self, base_route, model_name, model_route=\"model.h5\",\n",
    "                 train_folder=\"train\", validation_folder=\"val\", epochs=10,\n",
    "                 fine_tune: bool = False, fine_tune_epochs=5):\n",
    "\n",
    "        self.model = None\n",
    "        self.__base_model = None\n",
    "        self.__train_directory_iterator = None\n",
    "        self.__validation_directory_iterator = None\n",
    "\n",
    "        self.__width = self.__height = 64\n",
    "        self.__train_route = os.path.join(base_route, train_folder)\n",
    "        self.__validation_route = os.path.join(base_route, validation_folder)\n",
    "        self.__model_name = model_name\n",
    "        self.__model_route = model_route\n",
    "\n",
    "        self.__fine_tuning = fine_tune\n",
    "\n",
    "        self.__epochs = epochs\n",
    "        self.__batch_size = 64\n",
    "        self.__fine_tune_epochs = fine_tune_epochs\n",
    "\n",
    "        self.__early_stop = EarlyStopping(\n",
    "            monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "        self.__checkpoint = self._get_model_checkpoint()\n",
    "\n",
    "        self.train_size = 0\n",
    "        self.validation_size = 0\n",
    "        self.train_steps = 0\n",
    "        self.validation_steps = 0\n",
    "\n",
    "    def build(self):\n",
    "        self.__train_directory_iterator = self._get_directory_iterator(\n",
    "            self.__train_route, True)\n",
    "        self.__validation_directory_iterator = self._get_directory_iterator(\n",
    "            self.__validation_route)\n",
    "\n",
    "        self.train_size = self.__train_directory_iterator.samples\n",
    "        self.validation_size = self.__validation_directory_iterator.samples\n",
    "\n",
    "        self._build_model(self.__train_directory_iterator.num_classes)\n",
    "\n",
    "    def train(self):\n",
    "        if self.__fine_tuning:\n",
    "            self._set_fine_tune()\n",
    "        else:\n",
    "            self._set_transfer_learning()\n",
    "\n",
    "        self.__model.fit_generator(\n",
    "            self.__train_directory_iterator,\n",
    "            steps_per_epoch=self.train_steps,\n",
    "            epochs=self.__fine_tune_epochs,\n",
    "            validation_data=self.__validation_directory_iterator,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=[self.__checkpoint, self.__early_stop]\n",
    "        )\n",
    "\n",
    "        self.fit_all(train=self.__train_directory_iterator,\n",
    "                     val=self.__validation_directory_iterator)\n",
    "\n",
    "        self.__model.save(self.__model_route)\n",
    "\n",
    "        metrics = self.__model.evaluate_generator(\n",
    "            self.__validation_directory_iterator)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def fit_all(self, train, val):\n",
    "        for layer in self.__model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        self.__model.compile(optimizer=SGD(lr=0.01, momentum=0.6),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "        self.__model.fit_generator(\n",
    "            train,\n",
    "            steps_per_epoch=self.train_steps,\n",
    "            epochs=self.__epochs,\n",
    "            validation_data=val,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=[self.__checkpoint, self.__early_stop]\n",
    "        )\n",
    "\n",
    "    def _build_model(self, num_classes: int):\n",
    "\n",
    "        if self.__model_name == \"vgg19\":\n",
    "            self.__base_model = VGG19(weights='imagenet', include_top=False, input_shape=(\n",
    "                self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"resnet\":\n",
    "            self.__base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(\n",
    "                self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"densenet121\":\n",
    "            self.__base_model = DenseNet121(\n",
    "                weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"DenseNet201\":\n",
    "            self.__base_model = DenseNet201(\n",
    "                weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "\n",
    "        x = self.__base_model.output\n",
    "\n",
    "        x = Concatenate()(\n",
    "            [GlobalAveragePooling2D()(x), GlobalMaxPooling2D()(x)])\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(1024 / 2, activation='relu')(x)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        self.__model = Model(\n",
    "            inputs=self.__base_model.input, outputs=predictions)\n",
    "\n",
    "    def _set_transfer_learning(self):\n",
    "        for layer in self.__base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        self.__model.compile(\n",
    "            optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def _set_fine_tune(self):\n",
    "        layers_to_freeze = int(len(self.__base_model.layers) * 0.9)\n",
    "\n",
    "        for layer in self.__model.layers[:layers_to_freeze]:\n",
    "            layer.trainable = False\n",
    "        for layer in self.__model.layers[layers_to_freeze:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        self.__model.compile(\n",
    "            optimizer=SGD(lr=0.02, momentum=0.7),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def _get_model_checkpoint(self):\n",
    "        return ModelCheckpoint(\n",
    "            self.__model_route,\n",
    "            monitor='val_acc',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            period=1\n",
    "        )\n",
    "\n",
    "    def _get_directory_iterator(self, route, is_train: bool = False):\n",
    "      image_generator = image.ImageDataGenerator(rescale=1.0 / 255, horizontal_flip=is_train,\n",
    "                                                 vertical_flip=is_train)\n",
    "\n",
    "      return image_generator.flow_from_directory(\n",
    "          directory=route,\n",
    "          target_size=(self.__width, self.__height),\n",
    "          batch_size=self.batch_size,\n",
    "          class_mode=\"categorical\")\n",
    "\n",
    "    @property\n",
    "    def train_size(self):\n",
    "        return self.__train_size\n",
    "\n",
    "    @train_size.setter\n",
    "    def train_size(self, train_size):\n",
    "        self.__train_size = train_size\n",
    "        self.train_steps = math.ceil(self.train_size / self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def validation_size(self):\n",
    "        return self.__validation_size\n",
    "\n",
    "    @validation_size.setter\n",
    "    def validation_size(self, validation_size):\n",
    "        self.__validation_size = validation_size\n",
    "        self.validation_steps = math.ceil(\n",
    "            self.validation_size / self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.__batch_size\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, batch_size):\n",
    "        self.__batch_size = batch_size\n",
    "        self.train_steps = math.ceil(self.train_size / self.batch_size)\n",
    "        self.validation_steps = math.ceil(\n",
    "            self.validation_size / self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.__model\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self.__model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying feature extraction with VGG19 on one image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = ImageModel(base_route=\"tiny-imagenet-200\",\n",
    "                 epochs=20,\n",
    "                 train_folder=\"train\",\n",
    "                 validation_folder=\"val/images\",\n",
    "                 fine_tune=True,\n",
    "                 fine_tune_epochs=3,\n",
    "                 model_name=\"vgg19\",\n",
    "                 model_route=\"vgg19_2.h5\")\n",
    "vgg.build()\n",
    "vgg.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitthal/miniforge3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2022-12-05 11:59:17.804365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-05 11:59:17.804643: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574710816/574710816 [==============================] - 89s 0us/step\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model= tf.keras.applications.VGG19( include_top=True, weights=\"imagenet\", input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation=\"softmax\", )\n",
    "print(model.summary())\n",
    "model.save(\"vgg19.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b9603ab75704494434c4abe56997ef3bb46c839483ec68f7dba80f8b5009106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
