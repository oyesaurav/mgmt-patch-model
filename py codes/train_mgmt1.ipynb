{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"E:\\MGMT patch detection\\mgmt-patch-model\"\n",
    "os.chdir(main_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting patients with MGMT status available with struc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_t1_t2.shape after combining mgmt status(598, 1730)\n",
      "df_t1_t2.shape after selecting only available mgmt(256, 1730)\n"
     ]
    }
   ],
   "source": [
    "df_t1_t2 = pd.read_csv(\"./Extracted feat combined/t1_t2_flair_t1gd.csv\")\n",
    "df_t1_t2.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "df_mgmt = pd.read_csv(\"UPENN-GBM_clinical_info_v1.0.csv\")\n",
    "df_mgmt.rename(columns={'ID':'SubjectID'}, inplace=True)\n",
    "\n",
    "df_t1_t2 = df_t1_t2.merge(df_mgmt[['MGMT','SubjectID']], on='SubjectID', how='right')\n",
    "df_t1_t2 = df_t1_t2.dropna(axis=0)\n",
    "print(\"df_t1_t2.shape after combining mgmt status\" + str(df_t1_t2.shape))\n",
    "\n",
    "df_1 = df_t1_t2[df_t1_t2['MGMT'] == 'Unmethylated']\n",
    "df_2 = df_t1_t2[df_t1_t2['MGMT'] == 'Methylated']\n",
    "df_t1_t2 = pd.concat([df_2,df_1])\n",
    "print(\"df_t1_t2.shape after selecting only available mgmt\" + str(df_t1_t2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unmethylated    147\n",
       "Methylated      109\n",
       "Name: MGMT, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of methylated and unmethylated\n",
    "df_t1_t2.MGMT.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting : Methylated as 1 and Unmethylated as 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1_t2['MGMT']=df_t1_t2['MGMT'].apply(lambda a :1 if a=='Methylated' else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1042)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reducing features using Variance Threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "vt=VarianceThreshold(threshold=0.3)\n",
    "vt.fit(df_t1_t2.drop(['MGMT','SubjectID'],axis=1))\n",
    "df_t1_t2_vt=vt.transform(df_t1_t2.drop(['MGMT','SubjectID'],axis=1))\n",
    "df_t1_t2_vt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size - (204, 1042)\n",
      "test size - (52, 1042)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_t1_t2_vt, \n",
    "                                                    df_t1_t2.MGMT, test_size=0.20, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df_t1_t2['MGMT'])\n",
    "print(\"train size - \" + str(train_x.shape))\n",
    "print(\"test size - \" + str(test_x.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for rfe \n",
    "from sklearn.feature_selection import RFE\n",
    "def rfe_feature_selection(algo,X,y):\n",
    "  rfe=RFE(estimator=algo).fit(X,y)\n",
    "  rfe_sel_index=rfe.get_support(indices=True)\n",
    "  return rfe_sel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def rf(x,y):\n",
    "   select_feat = SelectFromModel(estimator= RandomForestClassifier()).fit(x,y)\n",
    "   feat_idx = select_feat.get_support(indices=True)\n",
    "   return feat_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_scaled = StandardScaler().fit(train_x)\n",
    "train_x_scaled = x_scaled.transform(train_x)\n",
    "test_x_scaled=x_scaled.transform(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross Validation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating the training data for getting indexes of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "k_folds=10\n",
    "cv_sel_idx_list=[]\n",
    "skfold=StratifiedKFold(n_splits=k_folds,random_state=42,shuffle=True)\n",
    "for train_idx,val_idx in skfold.split(train_x_scaled,train_y):\n",
    "    x_train = np.take(train_x_scaled,train_idx,axis=0) # This train is the train set in validation\n",
    "    x_val = np.take(train_x_scaled,val_idx,axis=0)\n",
    "    y_train = np.take(train_y,train_idx,axis=0)\n",
    "    y_val = np.take(train_y,val_idx,axis=0)\n",
    "    # cv_sel_idx=rfe_feature_selection(SVC(kernel='linear'),x_train,y_train)\n",
    "    cv_sel_idx=rf(x_train,y_train)\n",
    "    cv_sel_idx_list.append(cv_sel_idx)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatinating the selected indexes from cv_sel_idx_list\n",
    "concat_sel_idx=cv_sel_idx_list[0]\n",
    "for i in list(range(1,10)):\n",
    "    concat_sel_idx=np.concatenate((concat_sel_idx,cv_sel_idx_list[i]))\n",
    "    \n",
    "concat_sel_idx=np.unique(concat_sel_idx)\n",
    "concat_sel_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "k_folds=10\n",
    "skfold=StratifiedKFold(n_splits=k_folds,random_state=42,shuffle=True)\n",
    "sel_train_x=np.take(train_x_scaled,concat_sel_idx,axis=1)\n",
    "sel_test_x=np.take(test_x_scaled,concat_sel_idx,axis=1)\n",
    "metrics=[]\n",
    "for train_idx,val_idx in skfold.split(sel_train_x,train_y):\n",
    "    x_train = np.take(sel_train_x,train_idx,axis=0) # This train is the train set in validation\n",
    "    x_val = np.take(sel_train_x,val_idx,axis=0)\n",
    "    y_train = np.take(train_y,train_idx,axis=0)\n",
    "    y_val = np.take(train_y,val_idx,axis=0)\n",
    "    model_svc=SVC(kernel='poly',C=0.7)\n",
    "    model_svc.fit(x_train,y_train)\n",
    "    pred_val_y=model_svc.predict(x_val)\n",
    "    pred_test_y=model_svc.predict(sel_test_x)\n",
    "    metrics.append([accuracy_score(y_val,pred_val_y),\n",
    "                    accuracy_score(test_y,pred_test_y)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5714285714285714, 0.5576923076923077],\n",
       " [0.6190476190476191, 0.5384615384615384],\n",
       " [0.5714285714285714, 0.5769230769230769],\n",
       " [0.5714285714285714, 0.5769230769230769],\n",
       " [0.6, 0.5769230769230769],\n",
       " [0.55, 0.5769230769230769],\n",
       " [0.6, 0.5769230769230769],\n",
       " [0.55, 0.5769230769230769],\n",
       " [0.6, 0.5769230769230769],\n",
       " [0.55, 0.5769230769230769]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get selected feature idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.571153846153846 +/- 0.01231370045660162\n"
     ]
    }
   ],
   "source": [
    "metrics=np.array(metrics)\n",
    "avg_accuracy=np.mean(metrics,axis=0)\n",
    "std_accuracy=np.std(metrics,axis=0)\n",
    "print(\"Accuracy : \"+str(avg_accuracy[1])+\" +/- \"+str(std_accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# svc_feat_index = rfe_feature_selection(SVC(kernel='linear'), train_x_scaled, train_y)\n",
    "# svc_feat_index.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try with no split, predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# def test_score(model):\n",
    "#     sel_feat_idx=rfe_feature_selection(model, train_x_scaled, train_y, 1000, 10).get_support(indices=True)\n",
    "#     model.fit(np.take(train_x_scaled,sel_feat_idx,axis=1),train_y)\n",
    "#     test_x_scaled = x_scaled.transform(test_x)\n",
    "#     test_x_scaled_sel=np.take(test_x_scaled,sel_feat_idx,axis=1)\n",
    "#     y_pred=model.predict(test_x_scaled_sel)\n",
    "#     y_pred=np.where(y_pred>0.5,1,0)\n",
    "#     return accuracy_score(test_y,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# import xgboost as xgb\n",
    "# models_list=[LogisticRegression(max_iter=1000),\n",
    "#              SVC(kernel='linear'),\n",
    "#              DecisionTreeClassifier(),\n",
    "#              xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)] \n",
    "# for model in models_list:\n",
    "#     name=str(model).split('(')[0]\n",
    "#     score=str(test_score(model))\n",
    "#     print(name+' - '+score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC performs more accuracy on test data in one split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-c772e36d472f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-c772e36d472f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    from sklearn.\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### List of Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.\n",
    "models_list=[LogisticRegression(),SVC(kernel='linear')] \n",
    "\n",
    "### DataFrame of accuracies for all model wrt cross validation\n",
    "# df_acc=pd.DataFrame(columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation on 10Folds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Logistic Regression       SVM\n",
       "1  Validation Accuracy             0.666667  0.619048\n",
       "   Test Accuracy                   0.519231  0.576923\n",
       "2  Validation Accuracy             0.523810  0.523810\n",
       "   Test Accuracy                   0.557692  0.538462\n",
       "3  Validation Accuracy             0.523810  0.571429\n",
       "   Test Accuracy                   0.596154  0.615385\n",
       "4  Validation Accuracy             0.428571  0.476190\n",
       "   Test Accuracy                   0.576923  0.557692\n",
       "5  Validation Accuracy             0.500000  0.700000\n",
       "   Test Accuracy                   0.615385  0.596154\n",
       "6  Validation Accuracy             0.650000  0.500000\n",
       "   Test Accuracy                   0.576923  0.557692\n",
       "7  Validation Accuracy             0.550000  0.500000\n",
       "   Test Accuracy                   0.557692  0.576923\n",
       "8  Validation Accuracy             0.500000  0.500000\n",
       "   Test Accuracy                   0.538462  0.538462\n",
       "9  Validation Accuracy             0.500000  0.600000\n",
       "   Test Accuracy                   0.634615  0.673077\n",
       "10 Validation Accuracy             0.650000  0.700000\n",
       "   Test Accuracy                   0.557692  0.596154"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "# model_names=['Logistic Regression','SVM']\n",
    "# acc_list=['Validation Accuracy','Test Accuracy']\n",
    "# cv=10\n",
    "# kfd=StratifiedKFold(n_splits=cv)\n",
    "# print(\"Cross Validation on \"+str(cv)+\"Folds\")\n",
    "# df_model_acc=pd.DataFrame(columns=model_names,index=[[0,0],acc_list])\n",
    "# k=0\n",
    "# for train_idx,val_idx in kfd.split(train_x_scaled_sel,train_y):\n",
    "    \n",
    "#     x_train = np.take(train_x_scaled_sel,train_idx,axis=0)\n",
    "#     x_val = np.take(train_x_scaled_sel,val_idx,axis=0)\n",
    "#     y_train = np.take(train_y,train_idx,axis=0)\n",
    "#     y_val = np.take(train_y,val_idx,axis=0)\n",
    "#     val_accuracies=[]\n",
    "#     test_accuracies=[]\n",
    "    \n",
    "#     for model in models_list:\n",
    "#         history = model.fit(x_train,y_train)\n",
    "#         y_pred = history.predict(x_val)\n",
    "#         val_acc = accuracy_score(y_val,y_pred)\n",
    "#         # print(\"validation acc - \" + str(acc))\n",
    "\n",
    "#         y_pred_test=history.predict(test_x_scaled_sel)\n",
    "#         # y_pred_test=np.where(y_pred_test>0.5,1,0)\n",
    "#         test_acc = accuracy_score(test_y,y_pred_test)\n",
    "#         # print(\"Test acc - \" + str(test_acc))\n",
    "#         val_accuracies.append(val_acc)\n",
    "#         test_accuracies.append(test_acc)\n",
    "        \n",
    "#     df_model_acc=pd.concat([df_model_acc,\n",
    "#                             pd.DataFrame(columns=model_names,\n",
    "#                                          data=[val_accuracies,test_accuracies],\n",
    "#                                          index=[[k+1,k+1],acc_list])])\n",
    "#     k+=1\n",
    "# df_model_acc[2:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b2455c0773d8c26655dfdc47cb2724dbbc1b091978a8bf3cd237ee649eef30f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
